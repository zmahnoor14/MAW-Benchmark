{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b97891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# import pubchempy as pcp\n",
    "# import numpy as np\n",
    "# def isNaN(string):\n",
    "#     return string != string\n",
    "# import os\n",
    "# import glob\n",
    "# import re\n",
    "# from pybatchclassyfire import *\n",
    "# import csv \n",
    "# import time\n",
    "# import json\n",
    "# from pandas import json_normalize\n",
    "# import wget\n",
    "# import string\n",
    "# import urllib.parse\n",
    "# import openpyxl\n",
    "# import statistics\n",
    "# import sys\n",
    "# from itertools import chain\n",
    "# from rdkit import Chem\n",
    "# from rdkit import DataStructs\n",
    "# from rdkit.Chem import AllChem\n",
    "# from rdkit.Chem import rdFMCS\n",
    "# from rdkit.Chem import PandasTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eee961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## sirius postprocessing\n",
    "\n",
    "# # in case if SL and ALL are given\n",
    "#                     if len(files_for_mz)==2:\n",
    "\n",
    "#                         # if the SL file is before the ALL file\n",
    "#                         if len(files_for_mz[0])>len(files_for_mz[1]):\n",
    "\n",
    "#                             # extract the formula and structure files\n",
    "#                             json_dirSL = next(os.walk(files_for_mz[0]))[1]\n",
    "#                             sub_sub_dirSL_structure_can = files_for_mz[0] + \"/\" + json_dirSL[0]  + \"/structure_candidates.tsv\"                   \n",
    "#                             sub_sub_dirSL_formula_can = files_for_mz[0] + \"/\" + json_dirSL[0]  + \"/formula_candidates.tsv\" \n",
    "#                             SL_Canopus_csv = files_for_mz[0] + \"/canopus_summary.tsv\"\n",
    "\n",
    "\n",
    "#                             # extract the formula and structure files\n",
    "#                             json_dirALL = next(os.walk(files_for_mz[1]))[1]\n",
    "#                             sub_sub_dirALL_structure_can = files_for_mz[1] + \"/\" + json_dirALL[0] +\"/structure_candidates.tsv\"\n",
    "#                             sub_sub_dirALL_formula_can = files_for_mz[1] + \"/\" + json_dirALL[0] +\"/formula_candidates.tsv\"\n",
    "#                             ALL_Canopus_csv = files_for_mz[1] + \"/canopus_summary.tsv\"\n",
    "\n",
    "\n",
    "#                         # if the ALL file is before the SL file\n",
    "#                         elif len(files_for_mz[1]) >len(files_for_mz[0]):\n",
    "\n",
    "\n",
    "#                             # extract the formula and structure files\n",
    "#                             json_dirALL = next(os.walk(files_for_mz[0]))[1]\n",
    "#                             sub_sub_dirALL_structure_can = files_for_mz[0] + \"/\" + json_dirALL[0]  + \"/structure_candidates.tsv\"                   \n",
    "#                             sub_sub_dirALL_formula_can = files_for_mz[0] + \"/\" + json_dirALL[0]  + \"/formula_candidates.tsv\"\n",
    "#                             ALL_Canopus_csv = files_for_mz[0] + \"/canopus_summary.tsv\"\n",
    "\n",
    "\n",
    "#                             # extract the formula and structure files\n",
    "#                             json_dirSL = next(os.walk(files_for_mz[1]))[1]\n",
    "#                             sub_sub_dirSL_structure_can = files_for_mz[1] + \"/\" + json_dirSL[0] +\"/structure_candidates.tsv\"\n",
    "#                             sub_sub_dirSL_formula_can = files_for_mz[1] + \"/\" + json_dirALL[0]  + \"/formula_candidates.tsv\"\n",
    "#                             SL_Canopus_csv = files_for_mz[1] + \"/canopus_summary.tsv\"\n",
    "\n",
    "#                         # if both structure files exist and they have more than 0 rows\n",
    "#                         if os.path.exists(sub_sub_dirSL_structure_can) and len(pd.read_csv(sub_sub_dirSL_structure_can, sep = \"\\t\"))>0 and os.path.exists(sub_sub_dirALL_structure_can) and len(pd.read_csv(sub_sub_dirALL_structure_can, sep = \"\\t\"))>0:\n",
    "\n",
    "#                             # read strcuture and formula tsv files for both SL and ALL\n",
    "#                             SL_structure_csv = pd.read_csv(sub_sub_dirSL_structure_can, sep = \"\\t\")\n",
    "#                             SL_formula_csv = pd.read_csv(sub_sub_dirSL_formula_can, sep = \"\\t\")\n",
    "#                             SL_Canopus = pd.read_csv(SL_Canopus_csv, sep = \"\\t\")\n",
    "\n",
    "\n",
    "#                             ALL_structure_csv = pd.read_csv(sub_sub_dirALL_structure_can, sep = \"\\t\")\n",
    "#                             ALL_formula_csv = pd.read_csv(sub_sub_dirALL_formula_can, sep = \"\\t\")\n",
    "#                             ALL_Canopus = pd.read_csv(ALL_Canopus_csv, sep = \"\\t\")\n",
    "\n",
    "#                             # Add the structure and formula files together\n",
    "#                             for structure, rows in ALL_structure_csv.iterrows():\n",
    "#                                 for formula, rows in ALL_formula_csv.iterrows():\n",
    "#                                     if ALL_structure_csv[\"formulaRank\"][structure] == ALL_formula_csv[\"rank\"][formula]:\n",
    "#                                         ALL_structure_csv.loc[structure, 'SiriusScore'] = ALL_formula_csv['SiriusScore'][formula]\n",
    "#                                         ALL_structure_csv.loc[structure, 'numExplainedPeaks'] = ALL_formula_csv['numExplainedPeaks'][formula]\n",
    "#                                         ALL_structure_csv.loc[structure, 'explainedIntensity'] = ALL_formula_csv['explainedIntensity'][formula]\n",
    "#                                         ALL_structure_csv.loc[structure, \"SuspectListEntry\"] = \"FALSE\"\n",
    "#                                         if len(ALL_Canopus)>0:\n",
    "#                                             if ALL_formula_csv[\"molecularFormula\"][formula] == ALL_Canopus[\"molecularFormula\"][0]:\n",
    "#                                                 ALL_structure_csv.loc[structure, 'superclass'] = ALL_Canopus['superclass'][0]\n",
    "#                                                 ALL_structure_csv.loc[structure, 'class'] = ALL_Canopus['class'][0]\n",
    "#                                                 ALL_structure_csv.loc[structure, 'subclass'] = ALL_Canopus['subclass'][0]\n",
    "\n",
    "#                             # Add the structure and formula files together\n",
    "#                             for structure_sl, rows in SL_structure_csv.iterrows():\n",
    "#                                 for formula_sl, rows in SL_formula_csv.iterrows():\n",
    "#                                     if SL_structure_csv[\"formulaRank\"][structure_sl] == SL_formula_csv[\"rank\"][formula_sl]:\n",
    "#                                         SL_structure_csv.loc[structure_sl, 'SiriusScore'] = SL_formula_csv['SiriusScore'][formula_sl]\n",
    "#                                         SL_structure_csv.loc[structure_sl, 'numExplainedPeaks'] = SL_formula_csv['numExplainedPeaks'][formula_sl]\n",
    "#                                         SL_structure_csv.loc[structure_sl, 'explainedIntensity'] = SL_formula_csv['explainedIntensity'][formula_sl]\n",
    "#                                         SL_structure_csv.loc[structure_sl, \"SuspectListEntry\"] = \"TRUE\"   \n",
    "#                                         if len(SL_Canopus)>0:\n",
    "#                                             if SL_formula_csv[\"molecularFormula\"][formula_sl] == SL_Canopus[\"molecularFormula\"][0]:\n",
    "#                                                 SL_structure_csv.loc[structure_sl, 'superclass'] = SL_Canopus['superclass'][0]\n",
    "#                                                 SL_structure_csv.loc[structure_sl, 'class'] = SL_Canopus['class'][0]\n",
    "#                                                 SL_structure_csv.loc[structure_sl, 'subclass'] = SL_Canopus['subclass'][0] \n",
    "\n",
    "\n",
    "#                             # after formula and structure have been merged, merge SL and ALL results\n",
    "#                             all_sl_db = pd.concat([ALL_structure_csv, SL_structure_csv], ignore_index=True)\n",
    "#                             for str_sirius, row in all_sl_db.iterrows():\n",
    "#                                 if not str_can_score(all_sl_db, str_sirius):\n",
    "#                                     all_sl_db = all_sl_db.drop(str_sirius, inplace=False)\n",
    "\n",
    "#                             result_sirius_name = (sub_dir+\"results_for_\"+json_dirALL[0].split(\"_\")[-1]+\"_\"+\"structure.csv\")\n",
    "#                             msp.loc[mz, \"sirius_result_dir\"] = result_sirius_name.replace(input_dir, \".\")\n",
    "#                             all_sl_db.to_csv(result_sirius_name)\n",
    "\n",
    "#                         # if only ALL structure file exists and they have more than 0 rows\n",
    "#                         elif not (os.path.exists(sub_sub_dirSL_structure_can) and len(pd.read_csv(sub_sub_dirSL_structure_can, sep = \"\\t\"))>0) and os.path.exists(sub_sub_dirALL_structure_can) and len(pd.read_csv(sub_sub_dirALL_structure_can, sep = \"\\t\"))>0:\n",
    "#                             ALL_structure_csv = pd.read_csv(sub_sub_dirALL_structure_can, sep = \"\\t\")\n",
    "#                             ALL_formula_csv = pd.read_csv(sub_sub_dirALL_formula_can, sep = \"\\t\")\n",
    "#                             ALL_Canopus = pd.read_csv(ALL_Canopus_csv, sep = \"\\t\")\n",
    "\n",
    "#                             # Add the structure and formula files together\n",
    "#                             for structure, rows in ALL_structure_csv.iterrows():\n",
    "#                                 for formula, rows in ALL_formula_csv.iterrows():\n",
    "#                                     if ALL_structure_csv[\"formulaRank\"][structure] == ALL_formula_csv[\"rank\"][formula]:\n",
    "#                                         ALL_structure_csv.loc[structure, 'SiriusScore'] = ALL_formula_csv['SiriusScore'][formula]\n",
    "#                                         ALL_structure_csv.loc[structure, 'numExplainedPeaks'] = ALL_formula_csv['numExplainedPeaks'][formula]\n",
    "#                                         ALL_structure_csv.loc[structure, 'explainedIntensity'] = ALL_formula_csv['explainedIntensity'][formula]\n",
    "#                                         ALL_structure_csv.loc[structure, \"SuspectListEntry\"] = \"FALSE\"\n",
    "#                                         if len(ALL_Canopus)>0:\n",
    "#                                             if ALL_formula_csv[\"molecularFormula\"][formula] == ALL_Canopus[\"molecularFormula\"][0]:\n",
    "#                                                 ALL_structure_csv.loc[structure, 'superclass'] = ALL_Canopus['superclass'][0]\n",
    "#                                                 ALL_structure_csv.loc[structure, 'class'] = ALL_Canopus['class'][0]\n",
    "#                                                 ALL_structure_csv.loc[structure, 'subclass'] = ALL_Canopus['subclass'][0]\n",
    "#                             # scoring function\n",
    "#                             for str_siriusA, row in ALL_structure_csv.iterrows():\n",
    "#                                 if not str_can_score(ALL_structure_csv, str_siriusA):\n",
    "#                                     ALL_structure_csv = ALL_structure_csv.drop(str_siriusA, inplace=False)\n",
    "\n",
    "#                             result_sirius_name = (sub_dir+\"results_for_\"+json_dirALL[0].split(\"_\")[-1]+\"_\"+\"structure.csv\")\n",
    "#                             msp.loc[mz, \"sirius_result_dir\"] = result_sirius_name.replace(input_dir, \".\")\n",
    "#                             ALL_structure_csv.to_csv(result_sirius_name)\n",
    "\n",
    "#                         elif not(os.path.exists(sub_sub_dirSL_structure_can) and len(pd.read_csv(sub_sub_dirSL_structure_can, sep = \"\\t\"))>0 and os.path.exists(sub_sub_dirALL_structure_can) and len(pd.read_csv(sub_sub_dirALL_structure_can, sep = \"\\t\"))>0):\n",
    "#                             if os.path.exists(sub_sub_dirALL_formula_can) and len(pd.read_csv(sub_sub_dirALL_formula_can, sep = \"\\t\"))>0:\n",
    "#                                 ALL_formula_csv = pd.read_csv(sub_sub_dirALL_formula_can, sep = \"\\t\")\n",
    "#                                 ALL_Canopus = pd.read_csv(ALL_Canopus_csv, sep = \"\\t\")\n",
    "#                                 if len(ALL_Canopus)>0:\n",
    "#                                     for formula, rows in ALL_formula_csv.iterrows():\n",
    "#                                         ALL_formula_csv.loc[formula, 'superclass'] = ALL_Canopus['superclass'][0]\n",
    "#                                         ALL_formula_csv.loc[formula, 'class'] = ALL_Canopus['class'][0]\n",
    "#                                         ALL_formula_csv.loc[formula, 'subclass'] = ALL_Canopus['subclass'][0]\n",
    "\n",
    "#                                 for for_siriusA, row in ALL_formula_csv.iterrows():\n",
    "#                                     if not ALL_formula_csv['explainedIntensity'][for_siriusA] >= exp_int:\n",
    "#                                         ALL_formula_csv = ALL_formula_csv.drop(for_siriusA, inplace=False)\n",
    "\n",
    "#                                 result_sirius_name = (sub_dir+\"results_for_\"+json_dirALL[0].split(\"_\")[-1]+\"_\"+\"formula.csv\")\n",
    "#                                 msp.loc[mz, \"sirius_result_dir\"] = result_sirius_name.replace(input_dir, \".\")\n",
    "\n",
    "#                                 ALL_formula_csv.to_csv(result_sirius_name)\n",
    "\n",
    "#                             else:\n",
    "#                                 pass\n",
    "#                         else:\n",
    "#                             pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396db87f",
   "metadata": {},
   "source": [
    "## MetFrag Suspect List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16991cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make sure your Smiles entries in the suspect list csv are in a column named \"SMILES\"\n",
    "# def slist_metfrag(input_dir, slist_csv, name):\n",
    "#     \"\"\"slist_metfrag is used to create a txt file that contains a list of \n",
    "#     InChIKeys. This list is later used by MetFrag to use these compounds \n",
    "#     as a Suspect List.\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored. For this \n",
    "#     function this directory must contain a csv file that has a column \n",
    "#     named \"SMILES\".\n",
    "    \n",
    "#     slist_csv (str): This is the csv file that contains a column of \n",
    "#     \"SMILES\". Additionally this file can contain other information \n",
    "#     about the compounds, but for this function, column of \"SMILES\", \n",
    "#     named as \"SMILES\" is necessary.\n",
    "\n",
    "#     Returns:\n",
    "#     list: list of InChIKeys\n",
    "#     txt: a txt file of list of InChIKeys, is stored in input_dir\n",
    "    \n",
    "#     Usage:\n",
    "#     slist_metfrag(input_dir = \"/user/project/\", slist_csv = \n",
    "#     \"suspectlist.csv\")\n",
    "    \n",
    "#     \"\"\"\n",
    "#     sl = pd.read_csv(slist_csv)\n",
    "#     sl_mtfrag= []\n",
    "#     for i, rows in sl.iterrows():\n",
    "#         if i is not None:\n",
    "#             mols = Chem.MolFromSmiles(sl['SMILES'][i])\n",
    "#             try:\n",
    "#                 sl.loc[i, 'InChIKey'] = Chem.inchi.MolToInchiKey(mols)\n",
    "#                 sl_mtfrag.append(sl['InChIKey'][i])\n",
    "#             except Exception as e:\n",
    "#                 print(e)\n",
    "    \n",
    "#     with open((input_dir + \"/SL_\"+ name + '.txt'), 'w') as filehandle:\n",
    "#         for listitem in sl_mtfrag:\n",
    "#             filehandle.write('%s\\n' % listitem)\n",
    "#     return(sl_mtfrag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e680ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def spec_postproc(input_dir, Source = \"all\"):\n",
    "    \n",
    "#     \"\"\"spec_postproc function processes the resulst from dereplication \n",
    "#     using different spectral DBs. \n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "    \n",
    "#     Source (str): either \"mbank\" or \"hmdb\" or \"gnps\", or \"all\"\n",
    "\n",
    "#     Returns:\n",
    "    \n",
    "#     dataframe: of the paths of the processed DB results\n",
    "    \n",
    "    \n",
    "#     Usage:\n",
    "#     spec_postproc(input_dir = \"/user/project/\", Source = \"all\")\n",
    "\n",
    "#     \"\"\"\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "\n",
    "#     # empty lists of csv files paths for each database\n",
    "#     GNPScsvfiles = []\n",
    "#     HMDBcsvfiles = []\n",
    "#     MassBankcsvfiles = []\n",
    "    \n",
    "#     #list all files and directories\n",
    "#     for entry in os.listdir(input_dir):\n",
    "#         if os.path.isdir(os.path.join(input_dir, entry)):\n",
    "            \n",
    "#             # enter the directory with /spectral_dereplication/ results\n",
    "#             sub_dir = input_dir + entry + '/spectral_dereplication'\n",
    "#             if os.path.exists(sub_dir):\n",
    "#                 files = (glob.glob(sub_dir+'/*.csv'))\n",
    "\n",
    "#                 for f in files:\n",
    "#                     if 'gnps.' in f: \n",
    "#                         GNPScsvfiles.append(f)\n",
    "#                     if 'hmdb.' in f: \n",
    "#                         HMDBcsvfiles.append(f)\n",
    "#                     if 'mbank.' in f: \n",
    "#                         MassBankcsvfiles.append(f)\n",
    "                            \n",
    "    \n",
    "#     if Source == \"hmdb\" or Source == \"all\":\n",
    "\n",
    "#         if not os.path.exists(input_dir+\"structures.sdf\"):\n",
    "#             #download SDF structures\n",
    "#             os.system(\"wget -P \" + input_dir + \" https://hmdb.ca/system/downloads/current/structures.zip\")\n",
    "#             os.system(\"unzip \"+ input_dir + \"structures.zip\" + \" -d \" + input_dir)\n",
    "            \n",
    "#         # Load the sdf\n",
    "#         dframe = PandasTools.LoadSDF((input_dir+\"structures.sdf\"),\n",
    "#                                      idName='HMDB_ID',smilesName='SMILES',\n",
    "#                                      molColName='Molecule', includeFingerprints=False)\n",
    "        \n",
    "#         #### read sdf file from HMDB to collect names and smiles ####\n",
    "    \n",
    "#         #HMDB CSV Result file pre_processing\n",
    "        \n",
    "#         #open another csv path holding empty list, which will be filled \n",
    "#         #with post processed csv results\n",
    "#         HMDBcsvfiles2 = []\n",
    "        \n",
    "#         for k in HMDBcsvfiles:\n",
    "            \n",
    "#             # read the csv files\n",
    "#             hmdb_df = pd.read_csv(k)\n",
    "            \n",
    "#             # merge on basis of id, frame and hmdb result files\n",
    "#             SmilesHM = pd.merge(hmdb_df, dframe, left_on=hmdb_df.HMDBcompoundID, right_on=dframe.DATABASE_ID)\n",
    "            \n",
    "            \n",
    "#             for i, row in hmdb_df.iterrows():\n",
    "                \n",
    "#                 for j, row in SmilesHM.iterrows():\n",
    "                    \n",
    "#                     # where index for both match, add the name and SMILES\n",
    "#                     if hmdb_df['id_X'][i]== SmilesHM['id_X'][j]:\n",
    "#                         hmdb_df.loc[i, 'HMDBSMILES'] = SmilesHM['SMILES'][j]#add SMILES\n",
    "#                         hmdb_df.loc[i, 'HMDBcompound_name'] = SmilesHM[\"GENERIC_NAME\"][j]#add name\n",
    "#                         hmdb_df.loc[i, 'HMDBformula'] = SmilesHM[\"FORMULA\"][j]#add formula\n",
    "                \n",
    "#             csvname = (os.path.splitext(k)[0])+\"proc\"+\".csv\" # name for writing it in a new file\n",
    "#             hmdb_df.to_csv(csvname) #write\n",
    "#             HMDBcsvfiles2.append(csvname)# add to a list\n",
    "#             dict1 = {'HMDBr': HMDBcsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)\n",
    "        \n",
    "#     #MassBank CSV Result file pre_processing\n",
    "    \n",
    "#     if Source == \"mbank\" or Source == \"all\":\n",
    "        \n",
    "#         #open another csv path holding empty list, which will be filled \n",
    "#         #with post processed csv results\n",
    "#         MassBankcsvfiles2 = []\n",
    "        \n",
    "#         for l in MassBankcsvfiles:\n",
    "            \n",
    "#             # read mbank csv file\n",
    "#             mbank_df = pd.read_csv(l)\n",
    "            \n",
    "#             for i, row in mbank_df.iterrows():\n",
    "                \n",
    "#                 inchiK = str(mbank_df[\"MBinchiKEY\"][i])\n",
    "                \n",
    "#                 #extract inchikeys\n",
    "#                 y = pcp.get_compounds(inchiK, 'inchikey')#compound based on inchikey\n",
    "                \n",
    "#                 for compound in y:\n",
    "                    \n",
    "#                     #add smiles\n",
    "#                     smles = compound.isomeric_smiles   \n",
    "#                     mbank_df.loc[i, 'MBSMILES'] = smles\n",
    "                    \n",
    "#             csvname = (os.path.splitext(l)[0])+\"proc\"+\".csv\"\n",
    "#             mbank_df.to_csv(csvname)\n",
    "#             MassBankcsvfiles2.append(csvname)\n",
    "            \n",
    "#             dict1 = {'MBr': MassBankcsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)\n",
    "    \n",
    "#     # GNPS CSV Result file pre_processing\n",
    "#     if Source == \"gnps\" or Source == \"all\":\n",
    "#         #open another csv path holding empty list, which will be filled \n",
    "#         #with post processed csv results\n",
    "#         GNPScsvfiles2 = []\n",
    "#         #currently only these subsets are removed from the names from GNPS\n",
    "#         matches = [\"M+\",\"[M\", \"M-\", \"2M\", \"M*\" \"20.0\", \"50.0\", \"30.0\", \"40.0\", \"60.0\", \"70.0\", \"eV\", \"Massbank\"\n",
    "#                , \"Spectral\", \"Match\", \"to\", \"from\", \"NIST14\", \"MoNA\", '[IIN-based:',  '[IIN-based', 'on:', 'CCMSLIB00003136269]']\n",
    "\n",
    "#         for l in GNPScsvfiles:\n",
    "#             gnps_df = pd.read_csv(l)\n",
    "\n",
    "#             for i, row in gnps_df.iterrows():\n",
    "#                 # if compound name is present\n",
    "#                 if not isNaN(gnps_df['GNPScompound_name'][i]):\n",
    "#                     # split if there is a gap in the names\n",
    "#                     string_chng = (gnps_df['GNPScompound_name'][i].split(\" \"))\n",
    "\n",
    "#                     # create an empty list\n",
    "#                     newstr = []\n",
    "\n",
    "#                     # for each part of the string in the names\n",
    "#                     chng = []\n",
    "\n",
    "#                     for j in range(len(string_chng)):\n",
    "\n",
    "#                         # check if the substrings are present in the matches and no - is present\n",
    "#                         if not any(x in string_chng[j] for x in matches): #and not '-' == string_chng[j]:\n",
    "\n",
    "#                             # IF | and ! not in the substring\n",
    "#                             if '|' not in string_chng[j] or '!' not in string_chng[j]:\n",
    "#                                 newstr.append(string_chng[j])\n",
    "\n",
    "#                             # if | present in the substring   \n",
    "#                             elif '|' in string_chng[j]:\n",
    "\n",
    "#                                 #split the string\n",
    "#                                 jlen = string_chng[j].split(\"|\")\n",
    "#                                 #how many substrings are left now\n",
    "#                                 lst = len(jlen)-1\n",
    "#                                 #append this to chng\n",
    "#                                 chng.append(jlen[lst])\n",
    "#                                 break\n",
    "\n",
    "#                     # now append chng to newstr            \n",
    "#                     chng.append(' '.join(newstr))\n",
    "#                     #save this as the correct name\n",
    "#                     gnps_df.loc[i, \"corr_names\"] = chng[0]\n",
    "#                     if not isNaN(gnps_df['GNPSSMILES'][i]):\n",
    "#                         if chng == '':\n",
    "#                             break\n",
    "#                         elif gnps_df['GNPSSMILES'][i].isalpha():\n",
    "#                             s = pcp.get_compounds(chng[0], 'name')\n",
    "#                             if s:\n",
    "#                                 for comp in s:\n",
    "#                                     gnps_df[\"GNPSSMILES\"][i] = comp.isomeric_smiles\n",
    "#                             else:\n",
    "#                                 gnps_df[\"GNPSSMILES\"][i] = ''\n",
    "#                 else:\n",
    "#                     gnps_df[\"GNPSSMILES\"][i] = ''\n",
    "\n",
    "#             for i, row in gnps_df.iterrows():\n",
    "#                 if isNaN(gnps_df['GNPSSMILES'][i]):\n",
    "#                     if \"[\" in gnps_df['GNPScompound_name'][i].split(\" \")[-1]:\n",
    "#                         string_chng = (gnps_df['GNPScompound_name'][i].split(\"[\"))\n",
    "#                         #print(gnps_df['GNPScompound_name'][i])\n",
    "#                         keep_names = []\n",
    "#                         for j in range(len(string_chng)-1):\n",
    "#                             gnps_df.loc[i, \"corr_names\"] == string_chng[j]\n",
    "#                             s = pcp.get_compounds(string_chng[j], 'name')\n",
    "\n",
    "#                             if s:\n",
    "#                                 for comp in s:\n",
    "#                                     gnps_df[\"GNPSSMILES\"][i] = comp.isomeric_smiles\n",
    "#                             else:\n",
    "#                                 gnps_df[\"GNPSSMILES\"][i] = ''\n",
    "#                 if not isNaN(gnps_df['GNPSSMILES'][i]):\n",
    "#                     try:\n",
    "#                         sx = pcp.get_compounds(gnps_df['GNPSSMILES'][i], 'smiles')\n",
    "#                         if sx:\n",
    "#                             sx = str(sx)\n",
    "#                             comp = pcp.Compound.from_cid([int(x) for x in re.findall(r'\\b\\d+\\b', sx)])\n",
    "#                             gnps_df.loc[i, 'GNPSformula'] = comp.molecular_formula\n",
    "#                     except:\n",
    "#                         gnps_df.loc[i, 'GNPSformula'] = ''\n",
    "\n",
    "#             csvname = (os.path.splitext(l)[0])+\"proc\"+\".csv\"\n",
    "#             gnps_df.to_csv(csvname)\n",
    "#             GNPScsvfiles2.append(csvname)\n",
    "#             dict1 = {'GNPSr': GNPScsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)\n",
    "        \n",
    "\n",
    "#     if Source == \"all\":\n",
    "        \n",
    "#         dict1 = {'GNPSr': GNPScsvfiles2, 'HMDBr': HMDBcsvfiles2, 'MBr': MassBankcsvfiles2} \n",
    "#         df = pd.DataFrame(dict1)\n",
    "\n",
    "#         return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2d4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sirius_postProc2(input_dir, input_tablecsv):\n",
    "    \n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "#     \"\"\"sirius_postProc2 is the second part of the function \n",
    "#     sirius_postProc defined in R part of the workflow. This function\n",
    "#     re-checks the Suspect list, if present or given as a parameter, \n",
    "#     whether the candidates have a high similarity with compounds in\n",
    "#     Suspect List. It also calculates the Maximum Common Substructure\n",
    "#     (MCSS)\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored. For this \n",
    "#     function this directory must contain a csv file that has a column \n",
    "#     named \"SMILES\".\n",
    "    \n",
    "#     input_tablecsv (str): This is the table in csv format (defined in R), \n",
    "#     which stores a csv table containing columns \"mzml_files\", which \n",
    "#     contains liat of all input files with their relative paths, second\n",
    "#     column is \"ResultFileName\" which is a list of the corresponding\n",
    "#     result relative directories to each mzml files. Lastly, \"file_id\", \n",
    "#     contains a file directory. This table will be used to read the \n",
    "#     SIRIUS json files\n",
    "    \n",
    "\n",
    "#     Returns:\n",
    "#     csv: a result file with additional columns such as those for suspect\n",
    "#     list if one is used. It also adds columns on MCSS., named as \n",
    "#     \"input_dir/ResultFileName/insilico/SiriusResults.csv\"\n",
    "    \n",
    "    \n",
    "#     Usage:\n",
    "#     sirius_postProc2(input_dir = \"/user/project/\", \n",
    "#     input_table = \"/user/project/suspectlist.csv\")\n",
    "\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Describe the heavy atoms to be considered for MCSS\n",
    "#     heavy_atoms = ['C', 'N', 'P', 'O', 'S']\n",
    "    \n",
    "#     input_table = pd.read_csv(input_tablecsv)\n",
    "    \n",
    "#     for m, row in input_table.iterrows():\n",
    "        \n",
    "#         # Read the file result_dir/insilico/MS1DATAsirius.csv. \n",
    "#         # This file has been produced in R workflow and contains \n",
    "#         # SIRIUS results.\n",
    "\n",
    "#         file1 = pd.read_csv(input_dir + (input_table['ResultFileNames'][m] + '/insilico/MS1DATAsirius.csv').replace(\"./\", \"\"))\n",
    "        \n",
    "#         for i, row in file1.iterrows():\n",
    "            \n",
    "#             # if the entry has SMILES extracted for MCSS calculation\n",
    "#             if not isNaN(file1['SMILESforMCSS'][i]):\n",
    "                \n",
    "#                 # split the SMILES using |\n",
    "#                 top_smiles = file1['SMILESforMCSS'][i].split(\"|\")\n",
    "                \n",
    "#                 # if there are more than 1 smiles in the top smiles, \n",
    "#                 if len(top_smiles) > 1:\n",
    "#                     mol = []\n",
    "#                     for j in top_smiles:\n",
    "#                         n = Chem.MolFromSmiles(j)\n",
    "#                         mol.append(n)\n",
    "#                     # list of mol used to calaculate the MCSS\n",
    "#                     res = rdFMCS.FindMCS(mol)\n",
    "#                     sm_res = Chem.MolToSmiles(Chem.MolFromSmarts(res.smartsString))\n",
    "#                     # Check if the MCSS has one of the heavy atoms and whether they are\n",
    "#                     # more than 3\n",
    "#                     elem = [ele for ele in heavy_atoms if(ele in sm_res)]\n",
    "#                     if elem and len(sm_res)>=3:\n",
    "#                         file1.loc[i, 'MCSSstring'] = res.smartsString\n",
    "#                         file1.loc[i, 'MCSS_SMILES'] = Chem.MolToSmiles(Chem.MolFromSmarts(res.smartsString))\n",
    "                        \n",
    "                        \n",
    "#             if file1[\"FormulaRank\"][i] == 1.0:\n",
    "#                 sep = 'json/'\n",
    "#                 strpd = file1[\"dir\"][i].split(sep, 1)[0] +\"json/canopus_summary.tsv\"\n",
    "#                 if os.path.isfile(strpd):\n",
    "\n",
    "#                     canopus = pd.read_csv(strpd, sep='\\t')\n",
    "#                     if len(canopus) > 0:\n",
    "#                         #file1.loc[i, 'most_specific_class'] = canopus[\"most specific class\"][0]\n",
    "#                         #file1.loc[i, 'level _5'] = canopus[\"level 5\"][0]\n",
    "#                         file1.loc[i, 'subclass'] = canopus[\"subclass\"][0]\n",
    "#                         file1.loc[i, 'class'] = canopus[\"class\"][0]\n",
    "#                         file1.loc[i, 'superclass'] = canopus[\"superclass\"][0]\n",
    "#                         #file1.loc[i, 'all_classifications'] = canopus[\"all classifications\"][0]\n",
    "#                         file1.loc[i, 'Classification_Source'] = 'CANOPUS'\n",
    "                    \n",
    "        \n",
    "#         file1.to_csv(input_dir + (input_table['ResultFileNames'][m] + '/insilico/SiriusResults.csv').replace(\"./\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d1d7afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def metfrag_postproc(input_dir, input_tablecsv, sl= True):\n",
    "    \n",
    "    \n",
    "#     \"\"\"metfrag_postproc function re-checks the Suspect list, if present \n",
    "#     or given as a parameter, whether the candidates have a high \n",
    "#     similarity with compounds in Suspect List. It also calculates the \n",
    "#     Maximum Common Substructure (MCSS). This function adds top candidates\n",
    "#     from PubChem and KEGG as these two databases are used with MetFrag\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored. For this \n",
    "#     function this directory must contain a csv file that has a column \n",
    "#     named \"SMILES\".\n",
    "    \n",
    "#     input_tablecsv (str): This is the table in csv format (defined in R), \n",
    "#     which stores a csv table containing columns \"mzml_files\", which \n",
    "#     contains liat of all input files with their relative paths, second\n",
    "#     column is \"ResultFileName\" which is a list of the corresponding\n",
    "#     result relative directories to each mzml files. Lastly, \"file_id\", \n",
    "#     contains a file directory. This table will be used to read the \n",
    "#     MetFrag csv files\n",
    "\n",
    "#     Returns:\n",
    "#     csv: a result file with additional columns such as those for suspect\n",
    "#     list if one is used. It also adds columns on MCSS., named as \n",
    "#     \"input_dir/ResultFileName/insilico/MetFragResults.csv\". It \n",
    "#     contains columns for KEGG and PubChem\n",
    "    \n",
    "    \n",
    "#     Usage:\n",
    "#     metfrag_postproc(input_dir = \"/user/project/\", \n",
    "#     input_table = \"/user/project/suspectlist.csv\", sl = True, slistcsv)\n",
    "\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Describe the heavy atoms to be considered for MCSS\n",
    "#     heavy_atoms = ['C', 'N', 'P', 'O', 'S']\n",
    "    \n",
    "#     input_table = pd.read_csv(input_tablecsv)\n",
    "    \n",
    "#     for m, row in input_table.iterrows():\n",
    "        \n",
    "#         # read SIRIUS results:\n",
    "        \n",
    "#         #siriusResults = pd.read_csv(input_dir + (input_table['ResultFileNames'][m] + '/insilico/SiriusResults.csv'))\n",
    "    \n",
    "#         # Result directory\n",
    "#         result = input_dir + (input_table['ResultFileNames'][m] + \n",
    "#                                  '/insilico/MetFrag').replace(\"./\", \"\")\n",
    "\n",
    "#         # list of all the csv files in the result directory result_dir/inislico/MetFrag/\n",
    "#         files_met = (glob.glob(result+'/*.csv'))\n",
    "\n",
    "#         # read the csv file that contains all the features from the input .mzml file\n",
    "#         file1  = pd.read_csv(input_dir + (input_table['ResultFileNames'][m] + '/insilico/MS1DATA.csv').replace(\"./\", \"\"))\n",
    "    \n",
    "#         # for each feature in the MS1DATA.csv file\n",
    "#         for i, row in file1.iterrows():\n",
    "        \n",
    "#             # take id as a pattern to differentiate between different ids\n",
    "#             pattern = file1.loc[i, \"id_X\"]\n",
    "        \n",
    "#             #check which of the csv result files have the same pattern in their names\n",
    "#             results = [i for i in files_met if pattern in i]\n",
    "        \n",
    "#             # find which of the files with that id have KEGG in their names,\n",
    "#             KEGG = [i for i in results if \"KEGG\" in i]\n",
    "        \n",
    "#             # if kegg present in the name\n",
    "#             if KEGG:\n",
    "            \n",
    "#                 # read the KEGG csv file for that feature\n",
    "#                 KEGG_file = pd.read_csv((KEGG)[0])\n",
    "            \n",
    "#                 # if the KEGG file isn't empty\n",
    "#                 if len(KEGG_file)>0:\n",
    "                \n",
    "#                     # extract only the columns with >0.75 score\n",
    "#                     KEGG_file = KEGG_file.drop(KEGG_file[KEGG_file.Score < 0.98].index)\n",
    "                    \n",
    "#                     #s_best_kg = []\n",
    "#                     #for kg, rows in KEGG_file.iterrows():\n",
    "#                         #kg_smiles = Chem.MolToSmiles(Chem.MolFromInchi(KEGG_file[\"InChI\"][kg]))\n",
    "#                         #SSmsk = [Chem.MolFromSmiles(kg_smiles), Chem.MolFromSmiles(siriusResults[\"SMILES\"][0])]\n",
    "#                         #SSfpsk = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SSmsk]\n",
    "#                         #SStn2k = DataStructs.FingerprintSimilarity(SSfpsk[0],SSfpsk[1])\n",
    "#                         #s_best_kg.append(SStn2k)\n",
    "#                     #index_kg = np.argmax(s_best_kg)\n",
    "                        \n",
    "#                     # add the relevavnt information to the original MS1DATA csv\n",
    "#                     file1.loc[i, 'KG_ID'] = KEGG_file.loc[0, 'Identifier']\n",
    "#                     file1.loc[i, 'KG_Name'] = KEGG_file.loc[0, 'CompoundName']\n",
    "#                     file1.loc[i, 'KG_Formula'] = KEGG_file.loc[0, 'MolecularFormula']\n",
    "#                     file1.loc[i, 'KG_expPeaks'] = KEGG_file.loc[0, 'NoExplPeaks']\n",
    "#                     file1.loc[i, 'KG_SMILES'] = Chem.MolToSmiles(Chem.MolFromInchi(KEGG_file[\"InChI\"][0]))\n",
    "#                     file1.loc[i, 'KG_Score'] = KEGG_file.loc[0, 'Score']\n",
    "#                     if sl:\n",
    "#                         file1.loc[i, 'KGSL_Score'] = KEGG_file.loc[0, 'SuspectListScore']\n",
    "#                     file1.loc[i, 'KG_file'] = KEGG[0]\n",
    "                \n",
    "#                     #create empty list of KEGG top smiles\n",
    "#                     Kegg_smiles = []\n",
    "                \n",
    "#                     # extract only the InChI of the top 5\n",
    "#                     for j in KEGG_file[\"InChI\"][0:5].tolist():\n",
    "#                         # convert the InChI to SMILES\n",
    "#                         mol = Chem.MolToSmiles(Chem.MolFromInchi(j))\n",
    "#                         mol2 = Chem.MolFromSmiles(mol)\n",
    "#                         Kegg_smiles.append(mol2)\n",
    "#                     # if there are more than 1 top smiles\n",
    "#                     if len(Kegg_smiles) > 1:\n",
    "#                         #calculate the MCSS\n",
    "#                         res = rdFMCS.FindMCS(Kegg_smiles)\n",
    "#                         sm_res = Chem.MolToSmiles(Chem.MolFromSmarts(res.smartsString))\n",
    "#                         # if there are atleast 3 heavy atoms in the MCSS, then add it to the result file\n",
    "#                         elem = [ele for ele in heavy_atoms if(ele in sm_res)]\n",
    "#                         if elem and len(sm_res)>=3:\n",
    "#                             file1.loc[i, 'KG_MCSSstring'] = res.smartsString\n",
    "#                             file1.loc[i, 'KG_MCSS_SMILES'] = Chem.MolToSmiles(Chem.MolFromSmarts(res.smartsString))\n",
    "                            \n",
    "#             #start here for PubChem; find which of the files with that id have PubChem in their names,\n",
    "#             PubChem = [i for i in results if \"PubChem\" in i]\n",
    "            \n",
    "#             if PubChem:\n",
    "\n",
    "#                 PubChem_file = pd.read_csv(PubChem[0])\n",
    "                \n",
    "#                 # if more candidates\n",
    "#                 if len(PubChem_file)>0:\n",
    "                    \n",
    "#                     # take the ones with more than 0.80 score\n",
    "#                     PubChem_file = PubChem_file.drop(PubChem_file[PubChem_file.Score < 0.80].index)\n",
    "#                     #s_best_pb = []\n",
    "#                     #for pb, rows in PubChem_file.iterrows():\n",
    "#                         #SSmsp = [Chem.MolFromSmiles(PubChem_file[\"SMILES\"][pb]), Chem.MolFromSmiles(siriusResults[\"SMILES\"][0])]\n",
    "#                         #SSfpsp = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SSmsp]\n",
    "#                         #SStn2p = DataStructs.FingerprintSimilarity(SSfpsp[0],SSfpsp[1])\n",
    "#                         #s_best_pb.append(SStn2p)\n",
    "#                     #index_pb = np.argmax(s_best_pb)\n",
    "#                     # add the relavnt information to the original MS1DATA csv\n",
    "#                     file1.loc[i, 'PC_ID'] = PubChem_file.loc[0, 'Identifier']\n",
    "#                     file1.loc[i, 'PC_Name'] = PubChem_file.loc[0, 'IUPACName']\n",
    "#                     file1.loc[i, 'PC_Formula'] = PubChem_file.loc[0, 'MolecularFormula']\n",
    "#                     file1.loc[i, 'PC_expPeaks'] = PubChem_file.loc[0, 'NoExplPeaks']\n",
    "#                     file1.loc[i, 'PC_SMILES'] = PubChem_file[\"SMILES\"][0]\n",
    "#                     file1.loc[i, 'PC_Score'] = PubChem_file[\"Score\"][0]\n",
    "#                     if sl:\n",
    "#                         file1.loc[i, 'PCSL_Score'] = PubChem_file.loc[0, 'SuspectListScore']\n",
    "#                     file1.loc[i, 'PC_file'] = PubChem[0]\n",
    "                    \n",
    "#                     # empty object\n",
    "#                     Pubchem_smiles = []\n",
    "                    \n",
    "#                     # extract only the SMILES of the top 5\n",
    "#                     for j in PubChem_file[\"SMILES\"][0:5].tolist():\n",
    "                        \n",
    "#                         # Concert smiles to mol\n",
    "#                         sm2 = Chem.MolFromSmiles(j)\n",
    "#                         # store mol in Pubchem_smiles\n",
    "#                         Pubchem_smiles.append(sm2)\n",
    "                    \n",
    "#                     if len(Pubchem_smiles) > 1:\n",
    "#                         # calculate MCSS\n",
    "#                         res2 = rdFMCS.FindMCS(Pubchem_smiles)\n",
    "#                         sm_res = Chem.MolToSmiles(Chem.MolFromSmarts(res2.smartsString))\n",
    "#                         # If atleast 3 heavy atoms present\n",
    "#                         elem = [ele for ele in heavy_atoms if(ele in sm_res)]\n",
    "#                         if elem and len(sm_res)>=3:\n",
    "#                             file1.loc[i, 'PC_MCSSstring']= res2.smartsString\n",
    "#                             file1.loc[i, 'PC_MCSS_SMILES'] = Chem.MolToSmiles(Chem.MolFromSmarts(res2.smartsString))\n",
    "#         file1.to_csv(input_dir + (input_table['ResultFileNames'][m] + '/insilico/MetFragResults.csv').replace(\"./\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f3f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_insilico(input_dir, input_tablecsv, Source = \"all_insilico\"):\n",
    "    \n",
    "#     \"\"\"combine_insilico function combines the Sirius results from all\n",
    "#     result directories for each input mzml file. It does same for \n",
    "#     Metfrag.\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "    \n",
    "#     input_table (str): This is the table in csv format (defined in R), \n",
    "#     which stores a csv table containing columns \"mzml_files\", which \n",
    "#     contains liat of all input files with their relative paths, second\n",
    "#     column is \"ResultFileName\" which is a list of the corresponding\n",
    "#     result relative directories to each mzml files. Lastly, \"file_id\", \n",
    "#     contains a file directory. This table will be used to read the \n",
    "#     Sirius and MetFrag result csv files\n",
    "    \n",
    "#     Source (str): either \"SIRIUS\" or \"MetFrag\"\n",
    "\n",
    "#     Returns:\n",
    "    \n",
    "#     dataframe: of combined SIRIUS/MetFrag results\n",
    "    \n",
    "#     csv: stores the dataframe in a csv, named as \n",
    "#     \"input_dir/ResultFileName/MetabolomicsResults/SIRIUS_combined.csv\" \n",
    "#     OR/AND \n",
    "#     \"input_dir/ResultFileName/MetabolomicsResults/MetFrag_combined.csv\"\n",
    "    \n",
    "    \n",
    "#     Usage:\n",
    "#     combine_insilico(input_dir = \"/user/project/\", \n",
    "#     input_table = \"/user/project/suspectlist.csv\", Source = \"SIRIUS\")\n",
    "\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     input_table = pd.read_csv(input_tablecsv)\n",
    "#     # create a new directory to store all results /MetabolomicsResults/\n",
    "#     path = os.path.join(input_dir, \"MetabolomicsResults\")\n",
    "#     if not os.path.isdir(path):\n",
    "#         os.mkdir(path)    \n",
    "#     # if Sirius results are to be combined\n",
    "#     if Source == \"all_insilico\" or Source == \"SIRIUS\":\n",
    "        \n",
    "#         # store all files paths here\n",
    "#         all_files = []\n",
    "#         for n, row in input_table.iterrows():\n",
    "#             all_files.append(input_dir + input_table['ResultFileNames'][n].replace(\"./\", \"\") + '/insilico/SiriusResults.csv')\n",
    "        \n",
    "#         # store all dataframes of the results here\n",
    "#         li = []\n",
    "    \n",
    "#         for filename in all_files:\n",
    "#             df = pd.read_csv(filename, index_col=None, header=0)\n",
    "#             df[\"ResultFileNames\"] = filename\n",
    "#             li.append(df)\n",
    "            \n",
    "#         # join all resulst dataframe\n",
    "#         frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "#         frame.to_csv(input_dir + '/MetabolomicsResults/SIRIUS_combined.csv')       \n",
    "    \n",
    "#     # if MetFrag results are to be combined\n",
    "#     if Source == \"all_insilico\" or Source == \"MetFrag\":\n",
    "        \n",
    "#         # store all files paths here\n",
    "#         all_files = []\n",
    "#         for m, row in input_table.iterrows():\n",
    "#             all_files.append(input_dir + input_table['ResultFileNames'][m].replace(\"./\", \"\") + '/insilico/MetFragResults.csv')\n",
    "#         li = []\n",
    "\n",
    "#         for filename in all_files:\n",
    "#             df = pd.read_csv(filename, index_col=None, header=0)\n",
    "#             df[\"result_dir\"] = filename\n",
    "#             li.append(df)\n",
    "\n",
    "#         frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "#         frame.to_csv(input_dir+'MetabolomicsResults/MetFrag_combined.csv')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22f12d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_specdb(input_dir):\n",
    "    \n",
    "#     \"\"\"combine_specdb function combines all results from different\n",
    "#     spectral dbs. Can only be used if more than one db is used \n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "\n",
    "#     Returns:\n",
    "#     dataframe: of the paths of the merged results\n",
    "    \n",
    "    \n",
    "#     Usage:\n",
    "#     combine_specdb(input_dir)\n",
    "\n",
    "#     \"\"\"\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "\n",
    "    \n",
    "#     # empty lists of csv files paths for each database\n",
    "#     GNPScsvfiles2 = []\n",
    "#     HMDBcsvfiles2 = []\n",
    "#     MassBankcsvfiles2 = []\n",
    "    \n",
    "#     #list all files and directories\n",
    "#     for entry in os.listdir(input_dir):\n",
    "#         if os.path.isdir(os.path.join(input_dir, entry)):\n",
    "            \n",
    "#             # enter the directory with /spectral_dereplication/ results\n",
    "#             sub_dir = input_dir + entry + '/spectral_dereplication'\n",
    "#             if os.path.exists(sub_dir):\n",
    "#                 files = (glob.glob(sub_dir+'/*.csv'))\n",
    "\n",
    "#                 for f in files:\n",
    "#                     if 'gnpsproc.' in f: \n",
    "#                         GNPScsvfiles2.append(f)\n",
    "#                     if 'hmdbproc.' in f: \n",
    "#                         HMDBcsvfiles2.append(f)\n",
    "#                     if 'mbankproc.' in f: \n",
    "#                         MassBankcsvfiles2.append(f)\n",
    "   \n",
    "#     # if all results present\n",
    "#     if len(GNPScsvfiles2)>0 and len(HMDBcsvfiles2)>0 and len(MassBankcsvfiles2)>0:\n",
    "        \n",
    "#         dict1 = {'GNPSr': GNPScsvfiles2, 'HMDBr': HMDBcsvfiles2, 'MBr': MassBankcsvfiles2} \n",
    "#         df = pd.DataFrame(dict1)\n",
    "    \n",
    "#         Merged_Result_df = []\n",
    "#         for i, row in df.iterrows():\n",
    "#             CSVfileG = pd.read_csv(df[\"GNPSr\"][i])\n",
    "#             CSVfileH = pd.read_csv(df[\"HMDBr\"][i])\n",
    "#             CSVfileM = pd.read_csv(df[\"MBr\"][i])\n",
    "#             if os.path.exists(df[\"MBr\"][i]) and os.path.exists(df[\"HMDBr\"][i]) and os.path.exists(df[\"GNPSr\"][i]):\n",
    "#                 # merge on the basis of Idx\n",
    "#                 MergedRE = CSVfileG.merge(CSVfileH,on='id_X').merge(CSVfileM,on='id_X')\n",
    "#                 csvname = (df[\"GNPSr\"][i]).replace(\"gnpsproc\", \"mergedR\")\n",
    "#                 MergedRE.to_csv(csvname)\n",
    "#                 Merged_Result_df.append(csvname)\n",
    "                \n",
    "                \n",
    "#     # if only GNPS and MassBank           \n",
    "#     if len(GNPScsvfiles2)>0 and len(HMDBcsvfiles2)==0 and len(MassBankcsvfiles2)>0:\n",
    "#             dict1 = {'GNPSr': GNPScsvfiles2, 'MBr': MassBankcsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)\n",
    "#             Merged_Result_df = []\n",
    "#             for i, row in df.iterrows():\n",
    "#                 CSVfileG = pd.read_csv(df[\"GNPSr\"][i])\n",
    "#                 CSVfileM = pd.read_csv(df[\"MBr\"][i])\n",
    "#                 if os.path.exists(df[\"MBr\"][i]) and os.path.exists(df[\"GNPSr\"][i]):\n",
    "#                     # merge on the basis of Idx\n",
    "#                     MergedRE = CSVfileG.merge(CSVfileM,on='id_X')\n",
    "#                     csvname = (df[\"MBr\"][i]).replace(\"mbankproc\", \"mergedR\")\n",
    "#                     MergedRE.to_csv(csvname)\n",
    "#                     Merged_Result_df.append(csvname)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#     # if only GNPS and Hmdb\n",
    "#     if not isNaN(GNPScsvfiles2) and not isNaN(HMDBcsvfiles2) and isNaN(MassBankcsvfiles2):\n",
    "#             dict1 = {'GNPSr': GNPScsvfiles2, 'HMDBr': MassBankcsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)\n",
    "#             Merged_Result_df = []\n",
    "#             for i, row in df.iterrows():\n",
    "#                 CSVfileG = pd.read_csv(df[\"GNPSr\"][i])\n",
    "#                 CSVfileH = pd.read_csv(df[\"HMDBr\"][i])\n",
    "#                 if os.path.exists(df[\"HMDBr\"][i]) and os.path.exists(df[\"GNPSr\"][i]):\n",
    "#                     # merge on the basis of Idx\n",
    "#                     MergedRE = CSVfileG.merge(CSVfileH,on='id_X')\n",
    "#                     csvname = (df[\"GNPSr\"][i]).replace(\"gnpsproc\", \"mergedR\")\n",
    "#                     MergedRE.to_csv(csvname)\n",
    "#                     Merged_Result_df.append(csvname)\n",
    "                \n",
    "                \n",
    "                \n",
    "#     # if only MBANK and Hmdb\n",
    "#     if not isNaN(GNPScsvfiles2) and isNaN(HMDBcsvfiles2) and isNaN(MassBankcsvfiles2):\n",
    "#             dict1 = {'GNPSr': GNPScsvfiles2, 'HMDBr': MassBankcsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)   \n",
    "#             dict1 = {'GNPSr': GNPScsvfiles2, 'HMDBr': MassBankcsvfiles2} \n",
    "#             df = pd.DataFrame(dict1)\n",
    "#             Merged_Result_df = []\n",
    "#             for i, row in df.iterrows():\n",
    "#                 CSVfileG = pd.read_csv(df[\"MBr\"][i])\n",
    "#                 CSVfileH = pd.read_csv(df[\"HMDBr\"][i])\n",
    "#                 if os.path.exists(df[\"MBr\"][i]) and os.path.exists(df[\"HMDBr\"][i]):\n",
    "#                     # merge on the basis of Idx\n",
    "#                     MergedRE = CSVfileM.merge(CSVfileH,on='id_X')\n",
    "#                     csvname = (df[\"MBr\"][i]).replace(\"mbankproc\", \"mergedR\")\n",
    "#                     MergedRE.to_csv(csvname)\n",
    "#                     Merged_Result_df.append(csvname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a6f30f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_allspec(input_dir):\n",
    "    \n",
    "#     \"\"\"combine_allspec function combines all results from different\n",
    "#     spectral dbs. Can only be used if more than one db is used \n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "#     df (dataframe): dataframe from combine_specdb\n",
    "    \n",
    "#     Returns:\n",
    "#     dataframe: of the paths of the merged results from all files\n",
    "    \n",
    "#     Usage:\n",
    "#     combine_allspec(input_dir = \"usr/project/\", comb_df)\n",
    "\n",
    "#     \"\"\"\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "#     # create a new directory to store all results /MetabolomicsResults/\n",
    "#     path = os.path.join(input_dir, \"MetabolomicsResults\")\n",
    "#     if not os.path.isdir(path):\n",
    "#         os.mkdir(path)\n",
    "        \n",
    "        \n",
    "#     Mergedcsvfiles = []\n",
    "#     single_file = []\n",
    "    \n",
    "#     #list all files and directories\n",
    "#     for entry in os.listdir(input_dir):\n",
    "#         if os.path.isdir(os.path.join(input_dir, entry)):\n",
    "            \n",
    "#             # enter the directory with /spectral_dereplication/ results\n",
    "#             sub_dir = input_dir + entry + '/spectral_dereplication'\n",
    "#             if os.path.exists(sub_dir):\n",
    "#                 files = (glob.glob(sub_dir+'/*.csv'))\n",
    "\n",
    "#                 for f in files:\n",
    "#                     if 'mergedR.csv' in f: \n",
    "#                         Mergedcsvfiles.append(f)\n",
    "#                     else:\n",
    "#                         single_file.append(f)\n",
    "    \n",
    "#     if len(Mergedcsvfiles)>0:\n",
    "#         combined_csv = pd.concat([pd.read_csv(l) for l in Mergedcsvfiles], ignore_index=True)\n",
    "#         combined_csv.to_csv(input_dir + 'MetabolomicsResults/SD_post_processed_combined_results.csv')\n",
    "#         return(combined_csv)\n",
    "#     else:\n",
    "#         single_csv = pd.read_csv(single_file[0])\n",
    "#         single_csv.to_csv(input_dir + 'MetabolomicsResults/SD_post_processed_combined_results.csv')\n",
    "#         return(single_csv)\n",
    "    \n",
    "#     #for i, row in combined_csv.iterrows():\n",
    "#         #if combined_csv['GNPSSMILES'][i] == ' ' or isNaN(combined_csv['GNPSSMILES'][i]):\n",
    "#             #combined_csv['GNPSSMILES'][i] = ''\n",
    "            \n",
    "#     #for i, row in combined_csv.iterrows():\n",
    "#         #if not isNaN(combined_csv['MBinchiKEY'][i]):\n",
    "#             #try:\n",
    "#                 #y = pcp.get_compounds(combined_csv['MBinchiKEY'][i], 'inchikey')\n",
    "#                 #if len(y)>1:\n",
    "#                     #combined_csv['MBSMILES'][i] = y[0].isomeric_smiles\n",
    "#             #except:\n",
    "#                 #pass\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a41558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scoring_spec(input_dir, spec_file):\n",
    "    \n",
    "#     \"\"\"scoring_spec extracts the candidates with high scores from\n",
    "#     the results from combine_allspec function \n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "#     combined (dataframe): dataframe from combine_allspec\n",
    "    \n",
    "#     Returns:\n",
    "#     dataframe: of the all features and their results\n",
    "#     csv: CSV reuslt file named MetabolomicsResults/combinedSpecDB.csv\n",
    "#     which contains all the features and their Spec DB annotations\n",
    "    \n",
    "#     Usage:\n",
    "#     scoring_spec(input_dir = \"usr/project/\", combined)\n",
    "\n",
    "#     \"\"\"\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "#     # the scoring highly depends on the following information:\n",
    "#     # similarity scores should be higher than 0.75\n",
    "#     # intScore >=0.50\n",
    "#     # mzScore >= 0.50\n",
    "#     # ratio of the matchingpeaks by the totalpeaks in the query >= 0.50\n",
    "    \n",
    "#     combined = pd.read_csv(spec_file)\n",
    "    \n",
    "#     def HMDB_Scoring(db, i):\n",
    "#         if db['HMDBmax_similarity'][i] >= 0.75 and db['HMDBintScore'][i] >= 0.50 and db['HMDBmzScore'][i] >= 0.50 and db['HQMatchingPeaks'][i]/db['hQueryTotalPeaks'][i] >= 0.50:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "    \n",
    "#     def GNPS_Scoring(db, i):\n",
    "#         if db['GNPSmax_similarity'][i] >= 0.90 and db['GNPSintScore'][i] >= 0.50 and db['GNPSmzScore'][i] >= 0.50 and db['GQMatchingPeaks'][i]/db['gQueryTotalPeaks'][i] >= 0.50:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "    \n",
    "#     def MB_Scoring(db, i):\n",
    "#         if db['MBmax_similarity'][i] >= 0.50 and db['MBintScore'][i] >= 0.50 and db['MBmzScore'][i] >= 0.50 and db['MQMatchingPeaks'][i]/db['mQueryTotalPeaks'][i] >= 0.50:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "    \n",
    "#     for i, row in combined.iterrows():\n",
    "        \n",
    "        \n",
    "#         if 'HMDBSMILES' in combined.columns and 'MBSMILES' in combined.columns and 'GNPSSMILES' in combined.columns:\n",
    "            \n",
    "#             # if all DBs show good candidates accorindg to the scoring\n",
    "#             if HMDB_Scoring(combined, i) and GNPS_Scoring(combined, i) and MB_Scoring(combined, i) and not isNaN(combined['GNPSSMILES'][i]) and not isNaN(combined['MBSMILES'][i]) and not isNaN(combined['HMDBSMILES'][i]):\n",
    "            \n",
    "#                 # calulate the tanimoto similarity between the candidates from three DBs\n",
    "            \n",
    "#                 # hmdb and gnps\n",
    "#                 HGms = [Chem.MolFromSmiles(combined['HMDBSMILES'][i]), Chem.MolFromSmiles(combined['GNPSSMILES'][i])]\n",
    "#                 HGfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in HGms]\n",
    "#                 HGtn = DataStructs.FingerprintSimilarity(HGfps[0],HGfps[1])\n",
    "            \n",
    "#                 # gnps and mbank\n",
    "#                 GMms = [Chem.MolFromSmiles(combined['GNPSSMILES'][i]), Chem.MolFromSmiles(combined['MBSMILES'][i])]\n",
    "#                 GMfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in GMms]\n",
    "#                 GMtn = DataStructs.FingerprintSimilarity(GMfps[0],GMfps[1])\n",
    "            \n",
    "#                 # mbank and hmdb\n",
    "#                 HMms = [Chem.MolFromSmiles(combined['HMDBSMILES'][i]), Chem.MolFromSmiles(combined['MBSMILES'][i])]\n",
    "#                 HMfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in HMms]\n",
    "#                 HMtn = DataStructs.FingerprintSimilarity(HMfps[0],HMfps[1])\n",
    "            \n",
    "#                 # add the following columns\n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB, GNPS, MassBank'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = HGtn\n",
    "#                 combined.loc[i, 'tanimotoGM'] = GMtn\n",
    "#                 combined.loc[i, 'tanimotoHM'] = HMtn\n",
    "#                 combined.loc[i, 'occurence'] = 3\n",
    "        \n",
    "#             # if HMDB and GNPS show good candidates accorindg to the scoring\n",
    "#             if HMDB_Scoring(combined, i) and GNPS_Scoring(combined, i) and not MB_Scoring(combined, i) and not isNaN(combined['GNPSSMILES'][i]) and not isNaN(combined['HMDBSMILES'][i]):\n",
    "#                 HGms = [Chem.MolFromSmiles(combined['HMDBSMILES'][i]), Chem.MolFromSmiles(combined['GNPSSMILES'][i])]\n",
    "#                 HGfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in HGms]\n",
    "#                 HGtn = DataStructs.FingerprintSimilarity(HGfps[0],HGfps[1])\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB, GNPS'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = HGtn\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 2\n",
    "        \n",
    "#             # if MassBank and GNPS show good candidates accorindg to the scoring\n",
    "#             if not HMDB_Scoring(combined, i) and GNPS_Scoring(combined, i) and MB_Scoring(combined, i) and not isNaN(combined['MBSMILES'][i]) and not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                 GMms = [Chem.MolFromSmiles(combined['GNPSSMILES'][i]), Chem.MolFromSmiles(combined['MBSMILES'][i])]\n",
    "#                 GMfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in GMms]\n",
    "#                 GMtn = DataStructs.FingerprintSimilarity(GMfps[0],GMfps[1])\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'GNPS, MassBank'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoGM'] = GMtn\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 2\n",
    "        \n",
    "#             # if MassBank and HMDB show good candidates accorindg to the scoring\n",
    "#             if HMDB_Scoring(combined, i) and not GNPS_Scoring(combined, i) and MB_Scoring(combined, i) and not isNaN(combined['MBSMILES'][i]) and not isNaN(combined['HMDBSMILES'][i]):\n",
    "#                 HMms = [Chem.MolFromSmiles(combined['HMDBSMILES'][i]), Chem.MolFromSmiles(combined['MBSMILES'][i])]\n",
    "#                 HMfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in HMms]\n",
    "#                 HMtn = DataStructs.FingerprintSimilarity(HMfps[0],HMfps[1])\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB, MassBank'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoHM'] = HMtn\n",
    "#                 combined.loc[i, 'occurence'] = 2\n",
    "        \n",
    "#             # only HMDB\n",
    "#             if HMDB_Scoring(combined, i) and not GNPS_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "            \n",
    "#             # only GNPS\n",
    "#             if not HMDB_Scoring(combined, i) and GNPS_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'GNPS'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "        \n",
    "#             # only MassBank\n",
    "#             if not HMDB_Scoring(combined, i) and not GNPS_Scoring(combined, i) and MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'MassBank'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "        \n",
    "#             # none\n",
    "#             if not HMDB_Scoring(combined, i) and not GNPS_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "        \n",
    "#         if 'HMDBSMILES' not in combined.columns and 'MBSMILES' in combined.columns and 'GNPSSMILES' in combined.columns:\n",
    "\n",
    "#             # if MassBank and GNPS show good candidates accorindg to the scoring\n",
    "#             if GNPS_Scoring(combined, i) and MB_Scoring(combined, i) and not isNaN(combined['MBSMILES'][i]) and not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                 GMms = [Chem.MolFromSmiles(combined['GNPSSMILES'][i]), Chem.MolFromSmiles(combined['MBSMILES'][i])]\n",
    "#                 GMfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in GMms]\n",
    "#                 GMtn = DataStructs.FingerprintSimilarity(GMfps[0],GMfps[1])\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'GNPS, MassBank'\n",
    "#                 combined.loc[i, 'tanimotoGM'] = GMtn\n",
    "#                 combined.loc[i, 'occurence'] = 2\n",
    "#             # only GNPS\n",
    "#             if GNPS_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'GNPS'\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "        \n",
    "#             # only MassBank\n",
    "#             if not GNPS_Scoring(combined, i) and MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'MassBank'\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "                \n",
    "#             # none\n",
    "#             if not GNPS_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'tanimotoGM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "                \n",
    "                \n",
    "                \n",
    "#         if 'HMDBSMILES' in combined.columns and 'MBSMILES' not in combined.columns and 'GNPSSMILES' in combined.columns:\n",
    "#             # if HMDB and GNPS show good candidates accorindg to the scoring\n",
    "#             if HMDB_Scoring(combined, i) and GNPS_Scoring(combined, i) and not isNaN(combined['GNPSSMILES'][i]) and not isNaN(combined['HMDBSMILES'][i]):\n",
    "#                 HGms = [Chem.MolFromSmiles(combined['HMDBSMILES'][i]), Chem.MolFromSmiles(combined['GNPSSMILES'][i])]\n",
    "#                 HGfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in HGms]\n",
    "#                 HGtn = DataStructs.FingerprintSimilarity(HGfps[0],HGfps[1])\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB, GNPS'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = HGtn\n",
    "#                 combined.loc[i, 'occurence'] = 2\n",
    "        \n",
    "#             # only HMDB\n",
    "#             if HMDB_Scoring(combined, i) and not GNPS_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "            \n",
    "#             # only GNPS\n",
    "#             if not HMDB_Scoring(combined, i) and GNPS_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'GNPS'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "#             # none\n",
    "#             if not HMDB_Scoring(combined, i) and not GNPS_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'tanimotoHG'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "    \n",
    "#         if 'HMDBSMILES' in combined.columns and 'MBSMILES' in combined.columns and 'GNPSSMILES' not in combined.columns:\n",
    "            \n",
    "#             # if MassBank and HMDB show good candidates accorindg to the scoring\n",
    "#             if HMDB_Scoring(combined, i) and MB_Scoring(combined, i) and not isNaN(combined['MBSMILES'][i]) and not isNaN(combined['HMDBSMILES'][i]):\n",
    "#                 HMms = [Chem.MolFromSmiles(combined['HMDBSMILES'][i]), Chem.MolFromSmiles(combined['MBSMILES'][i])]\n",
    "#                 HMfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in HMms]\n",
    "#                 HMtn = DataStructs.FingerprintSimilarity(HMfps[0],HMfps[1])\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB, MassBank'\n",
    "#                 combined.loc[i, 'tanimotoHM'] = HMtn\n",
    "#                 combined.loc[i, 'occurence'] = 2\n",
    "                \n",
    "#             # only HMDB\n",
    "#             if HMDB_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB'\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "            \n",
    "#             # only MassBank\n",
    "#             if not HMDB_Scoring(combined, i) and MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'MassBank'\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "        \n",
    "#             # none\n",
    "#             if not HMDB_Scoring(combined, i) and not MB_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'tanimotoHM'] = np.nan\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "        \n",
    "        \n",
    "#         #If only HMDB was used\n",
    "        \n",
    "#         if 'HMDBSMILES' in combined.columns and 'MBSMILES' not in combined.columns and 'GNPSSMILES' not in combined.columns:\n",
    "#             # only HMDB\n",
    "#             if HMDB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'HMDB'\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "            \n",
    "#             # none\n",
    "#             if not HMDB_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "                \n",
    "                \n",
    "#         #If only MassBank was used      \n",
    "                \n",
    "#         if 'HMDBSMILES' not in combined.columns and 'MBSMILES' in combined.columns and 'GNPSSMILES' not in combined.columns:\n",
    "#             # only MassBank\n",
    "#             if MB_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'MassBank'\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "            \n",
    "#             # none\n",
    "#             if not MB_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "#         #If only GNPS was used\n",
    "        \n",
    "#         if 'HMDBSMILES' not in combined.columns and 'MBSMILES' not in combined.columns and 'GNPSSMILES' in combined.columns:\n",
    "#             # only GNPS\n",
    "#             if GNPS_Scoring(combined, i):\n",
    "        \n",
    "#                 combined.loc[i, 'annotation'] = 'GNPS'\n",
    "#                 combined.loc[i, 'occurence'] = 1\n",
    "            \n",
    "#             # none\n",
    "#             if not GNPS_Scoring(combined, i):\n",
    "#                 combined.loc[i, 'annotation'] = 'none'\n",
    "#                 combined.loc[i, 'occurence'] = 0\n",
    "                \n",
    "                \n",
    "#     combined.to_csv(input_dir + \"MetabolomicsResults/scoredSpecDB.csv\")\n",
    "#     return(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb0cd646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def metfrag_curation(input_dir, metfragcsv, sl = True):\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "    \n",
    "#     \"\"\"metfrag_curation checks which database produced results. If both \n",
    "#     did, it checks whether it was the same compound as candidate, if not,\n",
    "#     add PubChem or any of the two databases with similarity to Suspect\n",
    "#     list\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "#     metfragcsv (str): path to combined metfrag results:\n",
    "#     MetabolomicsResults/MetFrag_combined.csv\n",
    "    \n",
    "#     Returns:\n",
    "#     dataframe: dataframe of curated metfrag results\n",
    "#     csv: MetabolomicsResults/metfrag_curated.csv\n",
    "    \n",
    "#     Usage:\n",
    "#     metfrag_curation(input_dir = \"usr/project/\", \n",
    "#     metfragcsv = \"usr/project/MetabolomicsResults/MetFrag_combined.csv\")\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     metfrag = pd.read_csv(metfragcsv)\n",
    "#     for i, row in metfrag.iterrows():\n",
    "        \n",
    "        \n",
    "#         # If only KEGG\n",
    "#         if not isNaN(metfrag['KG_SMILES'][i]) and isNaN(metfrag['PC_SMILES'][i]):\n",
    "#             metfrag.loc[i, 'Annotation_M'] = 'KEGG'\n",
    "#             if sl:\n",
    "#                 if metfrag['KGSL_Score'][i]>=0.9:\n",
    "#                     metfrag.loc[i, 'Annotation_M'] = 'KEGG, SuspectList'\n",
    "#                 else:\n",
    "#                     metfrag.loc[i, 'Annotation_M'] = 'KEGG'\n",
    "    \n",
    "#         # If only Pubchem\n",
    "#         if not isNaN(metfrag['PC_SMILES'][i]) and isNaN(metfrag['KG_SMILES'][i]):\n",
    "#             metfrag.loc[i, 'Annotation_M'] = 'PubChem'\n",
    "#             if sl:\n",
    "#                 if metfrag['PCSL_Score'][i]>=0.9:\n",
    "#                     metfrag.loc[i, 'Annotation_M'] = 'PubChem, SuspectList'\n",
    "#                 else:\n",
    "#                     metfrag.loc[i, 'Annotation_M'] = 'PubChem'           \n",
    "        \n",
    "    \n",
    "#         # If both, calculate the similarity\n",
    "#         if not isNaN(metfrag['PC_SMILES'][i]) and not isNaN(metfrag['KG_SMILES'][i]):\n",
    "        \n",
    "#             PKms = [Chem.MolFromSmiles(metfrag['KG_SMILES'][i]), Chem.MolFromSmiles(metfrag['PC_SMILES'][i])]\n",
    "#             PKfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in PKms]\n",
    "#             PKtn = DataStructs.FingerprintSimilarity(PKfps[0],PKfps[1])\n",
    "        \n",
    "#             # if both are similar, add both\n",
    "#             if PKtn == 1:\n",
    "#                 metfrag.loc[i, 'Annotation_M'] = 'KEGG, PubChem'\n",
    "#                 if sl:\n",
    "#                     if metfrag['KGSL_Score'][i]>=0.9 and metfrag['PCSL_Score'][i]>=0.9:\n",
    "#                         metfrag.loc[i, 'Annotation_M'] = metfrag['Annotation_M'][i] + \", SuspectList\"\n",
    "        \n",
    "#             # if not similar:\n",
    "#             # check Suspect list score and Fragmenter Score\n",
    "            \n",
    "#             else:\n",
    "#                 if not isNaN(metfrag[\"KG_Score\"][i]):\n",
    "#                     metfrag.loc[i, 'Annotation_M'] = 'KEGG'\n",
    "#                 else:\n",
    "#                     metfrag.loc[i, 'Annotation_M'] = 'PubChem'\n",
    "                    \n",
    "                                \n",
    "#     metfrag.to_csv(input_dir + \"MetabolomicsResults/metfrag_curated.csv\")  \n",
    "#     return(metfrag)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f40848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sirius_curation(input_dir, siriuscsv, sl = True):\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "#     \"\"\"sirius_curation checks if candidate selected has a good score for \n",
    "#     explained intensity. It also checks if there was any similarity to\n",
    "#     a compound from Suspect list\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "#     siriuscsv (str): path to combined metfrag results:\n",
    "#     MetabolomicsResults/Sirius_combined.csv\n",
    "    \n",
    "#     Returns:\n",
    "#     dataframe: dataframe of curated sirius results\n",
    "#     csv: MetabolomicsResults/sirius_curated.csv\n",
    "    \n",
    "#     Usage:\n",
    "#     sirius_curation(input_dir = \"usr/project/\", \n",
    "#     siriuscsv = \"usr/project/MetabolomicsResults/Sirius_combined.csv\")\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     sirius = pd.read_csv(siriuscsv)\n",
    "#     for i, row in sirius.iterrows():\n",
    "    \n",
    "#         # If the explained intensity is greater than 0.70 and there is no suspect list entry\n",
    "#         if sirius['exp_int'][i] >= 0.70 and \"SIRIUS_SL\" not in sirius['Result'][i]:\n",
    "#             sirius.loc[i, 'Annotation_S'] = 'SIRIUS'\n",
    "#             #sirius.loc[i, 'SMILES_final'] = sirius['SMILES'][i]\n",
    "#         else:\n",
    "#             if sl:\n",
    "                \n",
    "#                 #If the explained intensity is greater than 0.70 and there is an entry from suspect list\n",
    "#                 if sirius['exp_int'][i] >= 0.70 and \"SIRIUS_SL\" in sirius['Result'][i]:\n",
    "#                     sirius.loc[i, 'Annotation_S'] = 'SIRIUS, SuspectList'\n",
    "#                     #sirius.loc[i, 'SMILES_final'] = sirius['SMILES'][i]\n",
    "    \n",
    "#                 # if the intensity is less thna 0.70 but it still is similar to an entry in Suspect list,\n",
    "#                 elif sirius['exp_int'][i] < 0.70 and \"SIRIUS_SL\" in sirius['Result'][i]:\n",
    "#                     sirius.loc[i, 'Annotation_S'] = 'SIRIUS, SuspectList'\n",
    "#                     #sirius.loc[i, 'SMILES_final'] = sirius['SMILES'][i]\n",
    "        \n",
    "#     sirius.to_csv(input_dir + \"MetabolomicsResults/sirius_curated.csv\")\n",
    "#     return(sirius)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a316d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combineSM(input_dir, metfragcsv, siriuscsv):\n",
    "    \n",
    "#     \"\"\"combineSM prioritizes Sirius and Suspect list over PubChem and\n",
    "#     KEGG\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "#     sirius (dataframe): result of sirius_curation\n",
    "#     metfrag (dataframe): result of metfrag_curation\n",
    "    \n",
    "#     Returns:\n",
    "#     dataframe: dataframe of combined curated sirius and metfrag results\n",
    "#     csv: \"MetabolomicsResults/combinedSM.csv\"\n",
    "    \n",
    "#     Usage:\n",
    "#     combineSM(input_dir = \"usr/project/\", metfrag, sirius)\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "    \n",
    "#     metfrag = pd.read_csv(metfragcsv)\n",
    "#     sirius = pd.read_csv(siriuscsv)\n",
    "#     S_M_CSV = pd.concat([sirius, metfrag], axis = 1, levels = [\"id_X\"])\n",
    "    \n",
    "#     for i, rows in S_M_CSV.iterrows():\n",
    "#         # if results has Sirius Structure annotation, and the explained inetnsity is >= 0.70, keep the annotation as is.\n",
    "#         if S_M_CSV[\"Result\"][i] == \"SIRIUS_STR\" and S_M_CSV['exp_int'][i] >= 0.70:\n",
    "#             S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i]\n",
    "            \n",
    "#             # to add to that annotation\n",
    "#             if not isNaN(S_M_CSV[\"Annotation_M\"][i]):\n",
    "#                 # if annotation has PubChem, by default add SIRIUS\n",
    "#                 if S_M_CSV[\"Annotation_M\"][i] == \"KEGG\":\n",
    "#                     SKms = [Chem.MolFromSmiles(S_M_CSV['SMILES'][i]), Chem.MolFromSmiles(S_M_CSV['KG_SMILES'][i])]\n",
    "#                     SKfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SKms]\n",
    "#                     SKtn = DataStructs.FingerprintSimilarity(SKfps[0],SKfps[1])\n",
    "\n",
    "#                     if SKtn >= 0.75:\n",
    "\n",
    "#                         S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i] +', KEGG'\n",
    "\n",
    "#                     else:\n",
    "#                         S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i]\n",
    "                        \n",
    "#                 # if annotation has PubChem, by default add SIRIUS\n",
    "#                 if S_M_CSV[\"Annotation_M\"][i] == \"PubChem\":\n",
    "#                     PSms = [Chem.MolFromSmiles(S_M_CSV['SMILES'][i]), Chem.MolFromSmiles(S_M_CSV['PC_SMILES'][i])]\n",
    "#                     PSfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in PSms]\n",
    "#                     PStn = DataStructs.FingerprintSimilarity(PSfps[0],PSfps[1])\n",
    "\n",
    "#                     # if similar strcutres, then add Pubchme and sirius\n",
    "#                     if PStn >= 0.7:\n",
    "\n",
    "#                         S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i] + ', PubChem'\n",
    "\n",
    "#                     # if not then just keep sirius\n",
    "#                     else:\n",
    "#                         S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i]\n",
    "                        \n",
    "                        \n",
    "#                 if S_M_CSV[\"Annotation_M\"][i] == \"KEGG, PubChem\":\n",
    "#                     SKms = [Chem.MolFromSmiles(S_M_CSV['SMILES'][i]), Chem.MolFromSmiles(S_M_CSV['KG_SMILES'][i])]\n",
    "#                     SKfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SKms]\n",
    "#                     SKtn = DataStructs.FingerprintSimilarity(SKfps[0],SKfps[1])\n",
    "#                     if SKtn >= 0.7:\n",
    "\n",
    "#                         S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i] +', KEGG, PubChem'\n",
    "\n",
    "#                     else:\n",
    "#                         S_M_CSV.loc[i, 'Annotation_C'] = S_M_CSV['Annotation_S'][i]\n",
    "#     S_M_CSV.to_csv(input_dir + \"MetabolomicsResults/combinedSM.csv\")\n",
    "#     return(S_M_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20f77bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def specDB_Curation(input_dir, combinedx, sl = True, db = \"all\"):\n",
    "    \n",
    "#     \"\"\"specDB_Curation prioritizes in the following manner: gnps>\n",
    "#     mbank>suspectlist>hmdb\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "    \n",
    "#     combined: dataframe from either suspectListScreening function if\n",
    "#     sl = True OR from scoring_spec if sl = False\n",
    "    \n",
    "#     Returns:\n",
    "#     dataframe: with curated Spectral DB results\n",
    "#     csv: \"MetabolomicsResults/curatedSDB.csv\"\n",
    "    \n",
    "#     Usage:\n",
    "#     specDB_Curation(input_dir = \"usr/project/\",combinedx, sl = True)\n",
    "\n",
    "#     \"\"\"\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "#     def HMDB_Scoring(db, i):\n",
    "#         if db['HMDBmax_similarity'][i] >= 0.75 and db['HMDBintScore'][i] >= 0.50 and db['HMDBmzScore'][i] >= 0.50 and db['HQMatchingPeaks'][i]/db['hQueryTotalPeaks'][i] >= 0.50:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "#     def GNPS_Scoring(db, i):\n",
    "#         if db['GNPSmax_similarity'][i] >= 0.90 and db['GNPSintScore'][i] >= 0.50 and db['GNPSmzScore'][i] >= 0.50 and db['GQMatchingPeaks'][i]/db['gQueryTotalPeaks'][i] >= 0.50:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "    \n",
    "#     def MB_Scoring(db, i):\n",
    "#         if db['MBmax_similarity'][i] >= 0.50 and db['MBintScore'][i] >= 0.50 and db['MBmzScore'][i] >= 0.50 and db['MQMatchingPeaks'][i]/db['mQueryTotalPeaks'][i] >= 0.50:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "#     combined = pd.read_csv(combinedx)\n",
    "    \n",
    "    \n",
    "#     # remove the similarity scores from low scoring candidates\n",
    "#     for i, row in combined.iterrows():\n",
    "#         if db == \"all\" or db == \"hg\" or db == \"hm\" or db == \"hmdb\":\n",
    "#             if not HMDB_Scoring(combined, i):\n",
    "#                 combined['HMDBcompoundID'][i] = np.nan\n",
    "#         if db == \"all\" or db == \"hg\" or db == \"gm\" or db == \"gnps\":\n",
    "#             if not GNPS_Scoring(combined, i):\n",
    "#                 combined['GNPSspectrumID'][i] = np.nan\n",
    "#         if db == \"all\" or db == \"gm\" or db == \"hm\" or db == \"mbank\":\n",
    "#             if not MB_Scoring(combined, i):\n",
    "#                 combined['MBspectrumID'][i] = np.nan\n",
    "    \n",
    "#     # if sl = True\n",
    "#     if sl:\n",
    "#         for i, row in combined.iterrows():\n",
    "#             # if all databases are used to generate results\n",
    "#             if db == \"all\":\n",
    "                \n",
    "#                 # if all dbs have results\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['MBspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "        \n",
    "#                     # entries with same candidate from all Spectral DBs\n",
    "#                     if combined['tanimotoHG'][i] == 1.0 and combined['tanimotoGM'][i] == 1.0 and combined['tanimotoHM'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, HMDB, MassBank'\n",
    "#                         #entries with same candidate in suspect list, as in all Spectral DBs\n",
    "#                         if combined['GLname'][i] == combined['HLname'][i]== combined['MLname'][i]:\n",
    "#                             combined.loc[i, 'Annotation'] = 'GNPS, HMDB, MassBank, SuspectList'\n",
    "                \n",
    "#                     # same candidate from GNPS and HMDB        \n",
    "#                     if combined['tanimotoHG'][i] == 1.0 and combined['tanimotoGM'][i] != 1.0 and combined['tanimotoHM'][i] != 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, HMDB'\n",
    "#                         # if its present in Suspect List\n",
    "#                         if combined['GLname'][i] == combined['HLname'][i]:\n",
    "#                             combined.loc[i, 'Annotation'] = 'GNPS, HMDB, SuspectList'\n",
    "        \n",
    "#                     # same candidate from GNPS and MassBank        \n",
    "#                     if combined['tanimotoHG'][i] != 1.0 and combined['tanimotoGM'][i] == 1.0 and combined['tanimotoHM'][i] != 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, MassBank'\n",
    "#                         # if its present in Suspect List\n",
    "#                         if combined['GLname'][i] == combined['MLname'][i]:\n",
    "#                             combined.loc[i, 'Annotation'] = 'GNPS, MassBank, SuspectList'\n",
    "                \n",
    "#                     # same candidate from MassBank and HMDB        \n",
    "#                     if combined['tanimotoHG'][i] != 1.0 and combined['tanimotoGM'][i] != 1.0 and combined['tanimotoHM'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'MassBank, HMDB'\n",
    "#                         # if its present in Suspect List\n",
    "#                         if combined['MLname'][i] == combined['HLname'][i]:\n",
    "#                             combined.loc[i, 'Annotation'] = 'HMDB, MassBank, SuspectList'\n",
    "                    \n",
    "#                     # only one database must be selected based on SuspectList annotation\n",
    "#                     if combined['tanimotoHG'][i] != 1.0 and combined['tanimotoGM'][i] != 1.0 and combined['tanimotoHM'][i] != 1.0:\n",
    "            \n",
    "#                         # only GNPS has SuspectList annotation\n",
    "#                         if not isNaN(combined['GLname'][i]):\n",
    "\n",
    "#                             combined.loc[i, 'Annotation'] = 'GNPS, SuspectList'\n",
    "            \n",
    "            \n",
    "#                         # only MassBank has SuspectList annotation\n",
    "#                         elif not isNaN(combined['MLname'][i]):\n",
    "#                             combined.loc[i, 'Annotation'] = 'MassBank, SuspectList'\n",
    "            \n",
    "            \n",
    "#                         # only HMDB has SuspectList annotation\n",
    "#                         #elif not isNaN(combined['HLname'][i]):\n",
    "#                             #combined.loc[i, 'Annotation'] = 'HMDB, SuspectList'\n",
    "            \n",
    "        \n",
    "#                         # all different annotations, take GNPS\n",
    "#                         else:\n",
    "#                             if not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                                 combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "#                             else:\n",
    "#                                 combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "    \n",
    "#                 #### When there is an annotation from two DBs #####\n",
    "\n",
    "#                 # only GNPS and HMDB\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and isNaN(combined['MBspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     if combined['tanimotoHG'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, HMDB'\n",
    "#                         if not isNaN(combined['GLname'][i]) and not isNaN(combined['HLname'][i]):\n",
    "#                             if combined['GLname'][i] == combined['HLname'][i]:\n",
    "#                                 combined.loc[i, 'Annotation'] = 'GNPS, HMDB, SuspectList'\n",
    "#                     else:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "#                         if not isNaN(combined['GLname'][i]):\n",
    "#                             combined.loc[i, 'Annotation'] = 'GNPS, SuspectList'\n",
    "#                         #elif not isNaN(combined['HLname'][i]):\n",
    "#                             #combined.loc[i, 'Annotation'] = 'HMDB, SuspectList'\n",
    "\n",
    "\n",
    "#                 # only GNPS and MassBank\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['MBspectrumID'][i]) and isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     if combined['tanimotoGM'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, MassBank'\n",
    "#                         if not isNaN(combined['GLname'][i]) and not isNaN(combined['MLname'][i]):\n",
    "#                             if combined['GLname'][i] == combined['MLname'][i]:\n",
    "#                                 combined.loc[i, 'Annotation'] = 'GNPS, MassBank, SuspectList'\n",
    "                                \n",
    "#                     else:\n",
    "#                         if not isNaN(combined['GLname'][i]):\n",
    "#                             combined.loc[i, 'Annotation'] = 'GNPS, SuspectList'\n",
    "#                         elif not isNaN(combined['MLname'][i]):\n",
    "#                             combined.loc[i, 'Annotation'] = 'MassBank, SuspectList'\n",
    "#                         elif not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                             combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "#                         else:\n",
    "#                             combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "\n",
    "#                 # only MassBank and HMDB\n",
    "\n",
    "#                 if isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['MBspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     if combined['tanimotoHM'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'HMDB, MassBank'\n",
    "#                         if not isNaN(combined['HLname'][i]) and not isNaN(combined['MLname'][i]):\n",
    "#                             if combined['HLname'][i] == combined['MLname'][i]:\n",
    "#                                 combined.loc[i, 'Annotation'] = 'HMDB, MassBank, SuspectList'\n",
    "                                \n",
    "#                     else:\n",
    "#                         if not isNaN(combined['MLname'][i]):\n",
    "#                             combined.loc[i, 'Annotation'] = 'MassBank, SuspectList'\n",
    "#                         #elif not isNaN(combined['MLname'][i]):\n",
    "#                             #combined.loc[i, 'Annotation'] = 'MassBank, SuspectList'\n",
    "#                         #elif not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                             #combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "#                         else:\n",
    "#                             combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "\n",
    "\n",
    "\n",
    "#                 ##### When there is an annotation from one DBs #####\n",
    "\n",
    "\n",
    "#                 # only GNPS\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and isNaN(combined['MBspectrumID'][i]) and isNaN(combined['HMDBcompoundID'][i]):\n",
    "\n",
    "#                     #If also SuspectList\n",
    "#                     if not isNaN(combined['GLname'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, SuspectList'\n",
    "#                     elif not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "\n",
    "#                 # only MassBank\n",
    "#                 if isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['MBspectrumID'][i]) and isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "#                     #If also SuspectList\n",
    "#                     if not isNaN(combined['MLname'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'MassBank, SuspectList'\n",
    "\n",
    "#                 # only HMDB\n",
    "#                 #if isNaN(combined['GNPSspectrumID'][i]) and isNaN(combined['MBspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     #combined.loc[i, 'Annotation'] = 'HMDB'\n",
    "#                     #If also SuspectList\n",
    "#                     #if not isNaN(combined['HLname'][i]):\n",
    "#                         #combined.loc[i, 'Annotation'] = 'HMDB, SuspectList'\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "            \n",
    "            \n",
    "#             # if GNPS AND MassBank databases are used to generate results\n",
    "#             if db == \"gm\":\n",
    "                \n",
    "#                 # only GNPS and MassBank\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['MBspectrumID'][i]):\n",
    "#                     if combined['tanimotoGM'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, MassBank'\n",
    "#                         if not isNaN(combined['GLname'][i]) and not isNaN(combined['MLname'][i]):\n",
    "#                             if combined['GLname'][i] == combined['MLname'][i]:\n",
    "#                                 combined.loc[i, 'Annotation'] = 'GNPS, MassBank, SuspectList'\n",
    "                                \n",
    "#                     else:\n",
    "#                         if not isNaN(combined['GLname'][i]):\n",
    "#                             combined.loc[i, 'Annotation'] = 'GNPS, SuspectList'\n",
    "#                         elif not isNaN(combined['MLname'][i]):\n",
    "#                             combined.loc[i, 'Annotation'] = 'MassBank, SuspectList'\n",
    "#                         elif not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                             combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "#                         else:\n",
    "#                             combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "\n",
    "                \n",
    "                \n",
    "#                 # only GNPS\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and isNaN(combined['MBspectrumID'][i]):\n",
    "\n",
    "#                     #If also SuspectList\n",
    "#                     if not isNaN(combined['GLname'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, SuspectList'\n",
    "#                     elif not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "\n",
    "#                 # only MassBank\n",
    "#                 if isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['MBspectrumID'][i]):\n",
    "#                     combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "#                     #If also SuspectList\n",
    "#                     if not isNaN(combined['MLname'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'MassBank, SuspectList'\n",
    "            \n",
    "            \n",
    "            \n",
    "#             # if GNPS AND HMDB databases are used to generate results\n",
    "#             if db == \"hg\":\n",
    "                \n",
    "#                 # only GNPS and HMDB\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     if combined['tanimotoHG'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, HMDB'\n",
    "#                         if not isNaN(combined['GLname'][i]) and not isNaN(combined['HLname'][i]):\n",
    "#                             if combined['GLname'][i] == combined['HLname'][i]:\n",
    "#                                 combined.loc[i, 'Annotation'] = 'GNPS, HMDB, SuspectList'\n",
    "#                     else:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "#                         if not isNaN(combined['GLname'][i]):\n",
    "#                             combined.loc[i, 'Annotation'] = 'GNPS, SuspectList'\n",
    "#                         #elif not isNaN(combined['HLname'][i]):\n",
    "#                             #combined.loc[i, 'Annotation'] = 'HMDB, SuspectList'\n",
    "\n",
    "#                 # only GNPS\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and isNaN(combined['HMDBcompoundID'][i]):\n",
    "\n",
    "#                     #If also SuspectList\n",
    "#                     if not isNaN(combined['GLname'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, SuspectList'\n",
    "#                     elif not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "#                 # only HMDB\n",
    "#                 #if isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     #combined.loc[i, 'Annotation'] = 'HMDB'\n",
    "#                     #If also SuspectList\n",
    "#                     #if not isNaN(combined['HLname'][i]):\n",
    "#                         #combined.loc[i, 'Annotation'] = 'HMDB, SuspectList'\n",
    "            \n",
    "#             # if MassBank AND HMDB databases are used to generate results\n",
    "#             if db == \"hm\":\n",
    "                \n",
    "#                 # only MassBank and HMDB\n",
    "\n",
    "#                 if not isNaN(combined['MBspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     if combined['tanimotoHM'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'HMDB, MassBank'\n",
    "#                         if not isNaN(combined['HLname'][i]) and not isNaN(combined['MLname'][i]):\n",
    "#                             if combined['HLname'][i] == combined['MLname'][i]:\n",
    "#                                 combined.loc[i, 'Annotation'] = 'HMDB, MassBank, SuspectList'\n",
    "                                \n",
    "#                     else:\n",
    "#                         if not isNaN(combined['MLname'][i]):\n",
    "#                             combined.loc[i, 'Annotation'] = 'MassBank, SuspectList'\n",
    "#                         else:\n",
    "#                             combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "                \n",
    "                \n",
    "                \n",
    "#                 # only MassBank\n",
    "#                 if not isNaN(combined['MBspectrumID'][i]) and isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "#                     #If also SuspectList\n",
    "#                     if not isNaN(combined['MLname'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'MassBank, SuspectList'\n",
    "\n",
    "#                 # only HMDB\n",
    "#                 #if isNaN(combined['MBspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     #combined.loc[i, 'Annotation'] = 'HMDB'\n",
    "#                     #If also SuspectList\n",
    "#                     #if not isNaN(combined['HLname'][i]):\n",
    "#                         #combined.loc[i, 'Annotation'] = 'HMDB, SuspectList'\n",
    "#             if db == \"gnps\":\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]):\n",
    "\n",
    "#                     #If also SuspectList\n",
    "#                     if not isNaN(combined['GLname'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, SuspectList'\n",
    "#                     elif not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "#             if db == \"mbank\":\n",
    "#                 # only MassBank\n",
    "#                 if not isNaN(combined['MBspectrumID'][i]):\n",
    "#                     combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "#                     #If also SuspectList\n",
    "#                     if not isNaN(combined['MLname'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'MassBank, SuspectList'\n",
    "#             #if db == \"hmdb\":\n",
    "#                 # only HMDB\n",
    "#                 #if not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     #combined.loc[i, 'Annotation'] = 'HMDB'\n",
    "#                     #If also SuspectList\n",
    "#                     #if not isNaN(combined['HLname'][i]):\n",
    "#                         #combined.loc[i, 'Annotation'] = 'HMDB, SuspectList'\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "#     else:\n",
    "#         for i, row in combined.iterrows():\n",
    "#             #if all databases were used\n",
    "#             if db == \"all\":\n",
    "#                 ##### When there is an annotaion from all DBs #####\n",
    "#                 #all entries with a high scoring annotation in all DBs,\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['MBspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     # entries with same candidate from all Spectral DBs\n",
    "#                     if combined['tanimotoHG'][i] == 1.0 and combined['tanimotoGM'][i] == 1.0 and combined['tanimotoHM'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, HMDB, MassBank'\n",
    "                \n",
    "#                     # same candidate from GNPS and HMDB        \n",
    "#                     if combined['tanimotoHG'][i] == 1.0 and combined['tanimotoGM'][i] != 1.0 and combined['tanimotoHM'][i] != 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, HMDB'\n",
    "        \n",
    "#                     # same candidate from GNPS and MassBank        \n",
    "#                     if combined['tanimotoHG'][i] != 1.0 and combined['tanimotoGM'][i] == 1.0 and combined['tanimotoHM'][i] != 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, MassBank'\n",
    "                \n",
    "#                     # same candidate from MassBank and HMDB        \n",
    "#                     if combined['tanimotoHG'][i] != 1.0 and combined['tanimotoGM'][i] != 1.0 and combined['tanimotoHM'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'MassBank, HMDB'\n",
    "                \n",
    "#                     # all different annotations, take GNPS\n",
    "#                     else:\n",
    "#                         if not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                             combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "#                         else:\n",
    "#                             combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "#                 ##### When there is an annotation from two DBs #####\n",
    "    \n",
    "    \n",
    "#                 # only GNPS and HMDB\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and isNaN(combined['MBspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     if combined['tanimotoHG'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, HMDB'\n",
    "#                     else:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "                    \n",
    "                    \n",
    "#                 # only GNPS and MassBank\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['MBspectrumID'][i]) and isNaN(combined['HMDBcompoundID'][i]):\n",
    "\n",
    "#                     if combined['tanimotoGM'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, MassBank'\n",
    "#                     else:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "    \n",
    "#                 # only MassBank and HMDB\n",
    "#                 if isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['MBspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     if combined['tanimotoHM'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'HMDB, MassBank'\n",
    "#                     else:\n",
    "#                         combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "#                 ##### When there is an annotation from one DBs #####\n",
    "    \n",
    "    \n",
    "#                 # only GNPS\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and isNaN(combined['MBspectrumID'][i]) and isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     if not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "        \n",
    "#                 # only MassBank\n",
    "#                 if isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['MBspectrumID'][i]) and isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "    \n",
    "#                 # only HMDB\n",
    "#                     #if isNaN(combined['GNPSspectrumID'][i]) and isNaN(combined['MBspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     #combined.loc[i, 'Annotation'] = 'HMDB'\n",
    "                \n",
    "            \n",
    "#             #if GNPS and MassBank databases were used\n",
    "#             if db == \"gm\":\n",
    "#                 # only GNPS and MassBank\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['MBspectrumID'][i]):\n",
    "#                     if combined['tanimotoGM'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, MassBank'\n",
    "#                     else:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "                    \n",
    "                \n",
    "#                 ##### When there is an annotation from one DBs #####\n",
    "#                 # only GNPS\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and isNaN(combined['MBspectrumID'][i]):\n",
    "#                     if not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "        \n",
    "#                 # only MassBank\n",
    "#                 if isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['MBspectrumID'][i]):\n",
    "#                     combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "                    \n",
    "                    \n",
    "#             # only GNPS and HMDB   \n",
    "#             if db == \"hg\":\n",
    "#                 ##### When there is an annotation from two DBs #####\n",
    "    \n",
    "    \n",
    "#                 # only GNPS and HMDB\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     if combined['tanimotoHG'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS, HMDB'\n",
    "#                     else:\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "                \n",
    "                \n",
    "#                 ##### When there is an annotation from one DBs #####\n",
    "    \n",
    "#                 # only GNPS\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]) and isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     if not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "#                 # only HMDB\n",
    "#                     #if isNaN(combined['GNPSspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     #combined.loc[i, 'Annotation'] = 'HMDB'\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "#             # only MassBank and HMDB        \n",
    "#             if db == \"hm\":\n",
    "#                 # only MassBank and HMDB\n",
    "#                 if not isNaN(combined['MBspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     if combined['tanimotoHM'][i] == 1.0:\n",
    "#                         combined.loc[i, 'Annotation'] = 'HMDB, MassBank'\n",
    "#                     else:\n",
    "#                         combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "                \n",
    "                \n",
    "                \n",
    "#                 # only MassBank\n",
    "#                 if not isNaN(combined['MBspectrumID'][i]) and isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "    \n",
    "#                 # only HMDB\n",
    "#                     #if isNaN(combined['MBspectrumID'][i]) and not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     #combined.loc[i, 'Annotation'] = 'HMDB'\n",
    "                \n",
    "#             if db == \"gnps\":\n",
    "#                 # only GNPS\n",
    "#                 if not isNaN(combined['GNPSspectrumID'][i]):\n",
    "#                     if not isNaN(combined['GNPSSMILES'][i]):\n",
    "#                         combined.loc[i, 'Annotation'] = 'GNPS'\n",
    "#             if db == \"mbank\":\n",
    "#                 # only MassBank\n",
    "#                 if not isNaN(combined['MBspectrumID'][i]):\n",
    "#                     combined.loc[i, 'Annotation'] = 'MassBank'\n",
    "#             #if db == \"hmdb\":\n",
    "#                 # only HMDB\n",
    "#                 #if not isNaN(combined['HMDBcompoundID'][i]):\n",
    "#                     #combined.loc[i, 'Annotation'] = 'HMDB'\n",
    "#     combined.to_csv(input_dir + \"MetabolomicsResults/curatedSDB.csv\")\n",
    "#     return(combined)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "738ecd88",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 1 (3678453104.py, line 266)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [12]\u001b[0;36m\u001b[0m\n\u001b[0;31m    #     return(bef_megaA)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 1\n"
     ]
    }
   ],
   "source": [
    "#def combine_CuratedR(input_dir, combinedSDBs, combinedSMs, data_type = \"standards\"):\n",
    "    \n",
    "#     \"\"\"combine_CuratedR prioritizes in the following manner: gnps>\n",
    "#     mbank>suspectlist>sirius>hmdb>metfrag\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "    \n",
    "#     curatedSDB: df from specDB_Curation\n",
    "#     combinedSM: df from combineSM\n",
    "    \n",
    "#     Returns:\n",
    "#     dataframe: with curated Spectral DB results and CDB (S+M) results\n",
    "#     csv: \"MetabolomicsResults/final_curation_without_classes.csv\"\n",
    "    \n",
    "#     Usage:\n",
    "#     combine_CuratedR(input_dir = \"usr/project/\", curatedSDB, combinedSM)\n",
    "\n",
    "#     \"\"\"\n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "\n",
    "#     combinedSDB = pd.read_csv(combinedSDBs)\n",
    "#     combinedSM = pd.read_csv(combinedSMs)\n",
    "#     mega = pd.concat([combinedSM, combinedSDB], axis = 1, levels = [\"id_X\"])\n",
    "    \n",
    "#     for i, row in mega.iterrows():\n",
    "    \n",
    "#         #if only compound database results\n",
    "#         if isNaN(mega['Annotation'][i]) and not isNaN(mega['Annotation_C'][i]):\n",
    "#             mega.loc[i, \"Annotation_Source\"] = mega['Annotation_C'][i]\n",
    "        \n",
    "#         # if only spectral db results\n",
    "#         if not isNaN(mega['Annotation'][i]) and isNaN(mega['Annotation_C'][i]):\n",
    "#             mega.loc[i, \"Annotation_Source\"] = mega['Annotation'][i]\n",
    "            \n",
    "#         # if both have results\n",
    "#         if not isNaN(mega['Annotation'][i]) and not isNaN(mega['Annotation_C'][i]):\n",
    "#             ########THREE OR FOUR SDB SOURCES########\n",
    "        \n",
    "#             #if three sdb sources or more\n",
    "#             # prioritize Spectral DBs\n",
    "#             if len(mega['Annotation'][i].split()) >= 3 and 'SIRIUS' in mega['Annotation_C'][i]:\n",
    "#                 if 'MassBank' in mega['Annotation'][i]:\n",
    "#                     SKms = [Chem.MolFromSmiles(mega['MBSMILES'][i]), Chem.MolFromSmiles(mega['SMILES'][i])]\n",
    "#                     SKfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SKms]\n",
    "#                     SKtn = DataStructs.FingerprintSimilarity(SKfps[0],SKfps[1])\n",
    "#                     if SKtn == 1.0:\n",
    "#                         print(SKtn)\n",
    "#                         mega.loc[i, \"Annotation_Source\"] = mega['Annotation'][i] + ', ' + mega['Annotation_C'][i]\n",
    "#                     else:\n",
    "#                         mega.loc[i, \"Annotation_Source\"] = mega['Annotation'][i]\n",
    "            \n",
    "#                 elif 'HMDB' in mega['Annotation'][i]:\n",
    "#                     SKms = [Chem.MolFromSmiles(mega['HMDBSMILES'][i]), Chem.MolFromSmiles(mega['SMILES'][i])]\n",
    "#                     SKfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SKms]\n",
    "#                     SKtn = DataStructs.FingerprintSimilarity(SKfps[0],SKfps[1])\n",
    "#                     if SKtn == 1.0:\n",
    "#                         mega.loc[i, \"Annotation_Source\"] = mega['Annotation'][i] + ', ' + mega['Annotation_C'][i]\n",
    "#                     else:\n",
    "#                         mega.loc[i, \"Annotation_Source\"] = mega['Annotation'][i]\n",
    "#             elif len(mega['Annotation'][i].split()) >= 3 and 'SIRIUS' not in mega['Annotation_C'][i]:\n",
    "#                 if 'KEGG' in mega['Annotation_C'][i]:\n",
    "#                     if 'MassBank' in mega['Annotation'][i]:\n",
    "#                         SKms = [Chem.MolFromSmiles(mega['MBSMILES'][i]), Chem.MolFromSmiles(mega['KG_SMILES'][i])]\n",
    "#                         SKfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SKms]\n",
    "#                         SKtn = DataStructs.FingerprintSimilarity(SKfps[0],SKfps[1])\n",
    "#                         if SKtn == 1.0:\n",
    "#                             mega.loc[i, \"Annotation_Source\"] = mega['Annotation'][i] + ', ' + mega['Annotation_C'][i]\n",
    "#                         else:\n",
    "#                             mega.loc[i, \"Annotation_Source\"] = mega['Annotation'][i]\n",
    "            \n",
    "#                     elif 'HMDB' in mega['Annotation'][i]:\n",
    "#                         SKms = [Chem.MolFromSmiles(mega['HMDBSMILES'][i]), Chem.MolFromSmiles(mega['KG_SMILES'][i])]\n",
    "#                         SKfps = [AllChem.GetMorganFingerprintAsBitVect(x,2, nBits=2048) for x in SKms]\n",
    "#                         SKtn = DataStructs.FingerprintSimilarity(SKfps[0],SKfps[1])\n",
    "#                         if SKtn == 1.0:\n",
    "#                             mega.loc[i, \"Annotation_Source\"] = mega['Annotation'][i] + ', ' + mega['Annotation_C'][i]\n",
    "#                         else:\n",
    "#                             mega.loc[i, \"Annotation_Source\"] = mega['Annotation'][i]\n",
    "#                 else:\n",
    "#                     mega.loc[i, \"Annotation_Source\"] = mega['Annotation'][i]\n",
    "            \n",
    "            \n",
    "            \n",
    "#             #######TWO OR ONE SDB SOURCE#########\n",
    "                \n",
    "#             #if both 2 SDBs and results from insilico tools\n",
    "#             elif len(mega['Annotation'][i].split()) <= 2:\n",
    "#                 mega.loc[i, \"Annotation_Source\"] = mega['Annotation_C'][i]\n",
    "                \n",
    "                \n",
    "#         # if no results from any databases\n",
    "#         if isNaN(mega['Annotation'][i]) and isNaN(mega['Annotation_C'][i]) and not isNaN(mega['Formula'][i]):\n",
    "#             mega.loc[i, \"Annotation_Source\"] = 'SIRIUS_Formula'\n",
    "        \n",
    "#     bef_mega = mega.loc[:,~mega.columns.duplicated()]\n",
    "#     for i, row in bef_mega.iterrows():\n",
    "#         if not isNaN(bef_mega['Annotation_Source'][i]):\n",
    "#             # check if SIRIUS is in the annotation source but keep in mind it shouldnt be SIRIUS_Formula\n",
    "#             if 'SIRIUS' in bef_mega['Annotation_Source'][i] and 'SIRIUS_Formula' not in bef_mega['Annotation_Source'][i]:\n",
    "#                 bef_mega.loc[i, 'SMILES_final'] = bef_mega['SMILES'][i]\n",
    "#                 bef_mega.loc[i,\"CompoundNames\"] = bef_mega['name'][i]\n",
    "#                 bef_mega['PC_MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['KG_MCSS_SMILES'][i] = np.nan\n",
    "#             elif 'KEGG' in bef_mega['Annotation_Source'][i]:\n",
    "#                 bef_mega.loc[i, 'SMILES_final'] = bef_mega['KG_SMILES'][i]\n",
    "#                 bef_mega.loc[i, 'CompoundNames'] = bef_mega['KG_Name'][i]\n",
    "#                 #bef_mega['most_specific_class'][i] = np.nan\n",
    "#                 #bef_mega['level _5'][i] = np.nan\n",
    "#                 bef_mega['subclass'][i] = np.nan\n",
    "#                 bef_mega['class'][i] = np.nan\n",
    "#                 bef_mega['superclass'][i] = np.nan\n",
    "#                 #bef_mega['all_classifications'][i] = np.nan\n",
    "#                 bef_mega['Classification_Source'][i] = np.nan\n",
    "#                 bef_mega['MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['PC_MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['Formula'][i] = np.nan\n",
    "            \n",
    "#             elif 'GNPS, SuspectList' in bef_mega['Annotation_Source'][i]:\n",
    "#                 bef_mega.loc[i,'SMILES_final'] = bef_mega['GLsmiles'][i]\n",
    "#                 bef_mega.loc[i, 'CompoundNames'] = bef_mega['GLname'][i]\n",
    "#                 bef_mega.loc[i, 'CompoundNames']\n",
    "#                 #bef_mega['most_specific_class'][i] = np.nan\n",
    "#                 #bef_mega['level _5'][i] = np.nan\n",
    "#                 bef_mega['subclass'][i] = np.nan\n",
    "#                 bef_mega['class'][i] = np.nan\n",
    "#                 bef_mega['superclass'][i] = np.nan\n",
    "#                 #bef_mega['all_classifications'][i] = np.nan\n",
    "#                 bef_mega['MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['Classification_Source'][i] = np.nan\n",
    "#                 bef_mega['PC_MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['KG_MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['Formula'][i] = np.nan\n",
    "        \n",
    "#             elif 'GNPS' in bef_mega['Annotation_Source'][i]:\n",
    "#                 bef_mega.loc[i,'SMILES_final'] = bef_mega['GNPSSMILES'][i]\n",
    "#                 bef_mega.loc[i, 'CompoundNames'] = bef_mega['GNPScompound_name'][i]\n",
    "#                 #bef_mega['most_specific_class'][i] = np.nan\n",
    "#                 #bef_mega['level _5'][i] = np.nan\n",
    "#                 bef_mega['subclass'][i] = np.nan\n",
    "#                 bef_mega['class'][i] = np.nan\n",
    "#                 bef_mega['superclass'][i] = np.nan\n",
    "#                 #bef_mega['all_classifications'][i] = np.nan\n",
    "#                 bef_mega['MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['Classification_Source'][i] = np.nan\n",
    "#                 bef_mega['PC_MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['KG_MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['Formula'][i] = np.nan\n",
    "#             elif 'MassBank' in bef_mega['Annotation_Source'][i]:\n",
    "#                 bef_mega.loc[i, 'SMILES_final'] = bef_mega['MBSMILES'][i]\n",
    "#                 bef_mega.loc[i, 'CompoundNames'] = bef_mega['MBcompound_name'][i]\n",
    "#                 #bef_mega['most_specific_class'][i] = np.nan\n",
    "#                 #bef_mega['level _5'][i] = np.nan\n",
    "#                 bef_mega['subclass'][i] = np.nan\n",
    "#                 bef_mega['class'][i] = np.nan\n",
    "#                 bef_mega['superclass'][i] = np.nan\n",
    "#                 #bef_mega['all_classifications'][i] = np.nan\n",
    "#                 bef_mega['Classification_Source'][i] = np.nan\n",
    "#                 bef_mega['MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['PC_MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['KG_MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['Formula'][i] = np.nan\n",
    "                \n",
    "                \n",
    "#             elif 'PubChem' in bef_mega['Annotation_Source'][i]:\n",
    "#                 bef_mega.loc[i, 'SMILES_final'] = bef_mega['PC_SMILES'][i]\n",
    "#                 bef_mega.loc[i, 'CompoundNames'] = bef_mega['PC_Name'][i]\n",
    "#                 #bef_mega['most_specific_class'][i] = np.nan\n",
    "#                 #bef_mega['level _5'][i] = np.nan\n",
    "#                 bef_mega['subclass'][i] = np.nan\n",
    "#                 bef_mega['class'][i] = np.nan\n",
    "#                 bef_mega['superclass'][i] = np.nan\n",
    "#                 #bef_mega['all_classifications'][i] = np.nan\n",
    "#                 bef_mega['Classification_Source'][i] = np.nan\n",
    "#                 bef_mega['MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['KG_MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['Formula'][i] = np.nan\n",
    "            \n",
    "#             elif 'HMDB' in bef_mega['Annotation_Source'][i]:\n",
    "#                 bef_mega.loc[i, 'SMILES_final'] = bef_mega['HMDBSMILES'][i]\n",
    "#                 bef_mega.loc[i, 'CompoundNames'] = bef_mega['HMDBcompound_name'][i]\n",
    "#                 #bef_mega['most_specific_class'][i] = np.nan\n",
    "#                 #bef_mega['level _5'][i] = np.nan\n",
    "#                 bef_mega['subclass'][i] = np.nan\n",
    "#                 bef_mega['class'][i] = np.nan\n",
    "#                 bef_mega['superclass'][i] = np.nan\n",
    "#                 #bef_mega['all_classifications'][i] = np.nan\n",
    "#                 bef_mega['Classification_Source'][i] = np.nan\n",
    "#                 bef_mega['MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['PC_MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['KG_MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['Formula'][i] = np.nan\n",
    "                \n",
    "                \n",
    "#             elif 'SIRIUS_Formula' in bef_mega['Annotation_Source'][i]:\n",
    "#                 bef_mega['PC_MCSS_SMILES'][i] = np.nan\n",
    "#                 bef_mega['KG_MCSS_SMILES'][i] = np.nan\n",
    "                \n",
    "                \n",
    "#     bef_megaA = bef_mega[['id_X', \n",
    "#                           'premz', \n",
    "#                           'rtmed', \n",
    "#                           'rtmean',\n",
    "#                           'int', \n",
    "#                           'col_eng', \n",
    "#                           'pol', \n",
    "#                           'SMILES_final', \n",
    "#                           'CompoundNames', \n",
    "#                           'MCSS_SMILES', \n",
    "#                           'PC_MCSS_SMILES', \n",
    "#                           'KG_MCSS_SMILES', \n",
    "#                           'subclass', \n",
    "#                           'class', \n",
    "#                           'superclass', \n",
    "#                           'Classification_Source', \n",
    "#                           'Annotation_Source'\n",
    "#                          ]]\n",
    "            \n",
    "#     bef_megaA.rename(columns = {'SMILES_final':'SMILES'}, inplace = True)\n",
    "    \n",
    "    \n",
    "#     Standards = ['Experimental']\n",
    "#     SpectralDB = ['GNPS', 'HMDB', 'MassBank']\n",
    "#     CompoundDB = ['SuspectList', 'SIRIUS', 'KEGG', 'PubChem']\n",
    "#     Formula = ['SIRIUS_Formula']\n",
    "\n",
    "    \n",
    "#     #bef_megaA['MSI_Level'] = np.nan\n",
    "#     for i, rows in bef_megaA.iterrows():\n",
    "        \n",
    "        \n",
    "#         if not isNaN(bef_megaA['Annotation_Source'][i]):\n",
    "            \n",
    "#             if data_type == \"standards\":\n",
    "#                 bef_megaA.loc[i, 'Annotation_Source'] = bef_megaA['Annotation_Source'][i] + ', Experimental'\n",
    "\n",
    "#                 if any(x in bef_megaA['Annotation_Source'][i] for x in SpectralDB):\n",
    "#                     bef_megaA.loc[i, 'MSI_Level'] = 'Level_1'\n",
    "                    \n",
    "#                 elif any(x in bef_megaA['Annotation_Source'][i] for x in CompoundDB) and not any(x in bef_megaA['Annotation_Source'][i] for x in Formula):\n",
    "#                     bef_megaA.loc[i, 'MSI_Level'] = 'Level_2/Level_3'\n",
    "                    \n",
    "#                 elif any(x in bef_megaA['Annotation_Source'][i] for x in Formula):\n",
    "#                     bef_megaA.loc[i, 'MSI_Level'] = 'Level_4'\n",
    "                    \n",
    "#             else:\n",
    "\n",
    "#                 if any(x in bef_megaA['Annotation_Source'][i] for x in SpectralDB):\n",
    "#                     bef_megaA.loc[i, 'MSI_Level'] = 'Level_2'\n",
    "                    \n",
    "#                 elif any(x in bef_megaA['Annotation_Source'][i] for x in CompoundDB) and not any(x in bef_megaA['Annotation_Source'][i] for x in Formula):\n",
    "#                     bef_megaA.loc[i, 'MSI_Level'] = 'Level_3'\n",
    "                    \n",
    "#                 elif any(x in bef_megaA['Annotation_Source'][i] for x in Formula):\n",
    "#                     bef_megaA.loc[i, 'MSI_Level'] = 'Level_4'\n",
    "                \n",
    "#         else:\n",
    "#             bef_megaA.loc[i, 'MSI_Level'] = 'Level_5'\n",
    "            \n",
    "                \n",
    "    \n",
    "            \n",
    "#     bef_megaA.to_csv(input_dir + \"MetabolomicsResults/final_curation_without_classes.csv\")\n",
    "#     return(bef_megaA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acafaa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def suspectListScreening(input_dir, slistcsv, SpectralDB_Results, db = \"all\"):\n",
    "    \n",
    "#     \"\"\"suspectListScreening runs tanoimoto similarity score to between\n",
    "#     compounds from the results from spectral DBs and suspect list\n",
    "\n",
    "#     Parameters:\n",
    "#     input_dir (str): This is the input directory where all the .mzML \n",
    "#     files and their respective result directories are stored.\n",
    "#     slistcsv (str): path to suspect list\n",
    "#     SpectralDB_Results (dataframe): dataframe from scoring_spec\n",
    "#     db(str): can be all, gnps, mbank, hmdb, gm, hg, hm\n",
    "    \n",
    "#     Returns:\n",
    "#     dataframe: all features and specDB reults and suspect list screening \n",
    "#     results\n",
    "#     csv: CSV reuslt file named MetabolomicsResults/SpecDBvsSL.csv\n",
    "#     which contains all the features and their Spec DB annotations\n",
    "#     and suspect list occurences if any\n",
    "    \n",
    "#     Usage:\n",
    "#     suspectListScreening(input_dir = \"usr/project/\",\n",
    "#     slistcsv = \"usr/project/suspect_list.csv\", \n",
    "#     SpectralDB_Results)\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     SpectralDB_Results = pd.read_csv(SpectralDB_Results)\n",
    "#     Suspect_list = pd.read_csv(slistcsv)\n",
    "    \n",
    "#     def isNaN(string):\n",
    "#         return string != string\n",
    "#     if db == \"hmdb\" or db == \"hm\" or db == \"hg\" or db == \"all\":\n",
    "        \n",
    "#         # add columns to the result from scoring_spec\n",
    "#         # these columns are for high similiarity canidtes between the databases and suspect list\n",
    "#         SpectralDB_Results['HLsmiles'] = np.nan\n",
    "#         SpectralDB_Results['HLname'] = np.nan\n",
    "\n",
    "#         for i, row in SpectralDB_Results.iterrows():\n",
    "#             if not isNaN(SpectralDB_Results['HMDBSMILES'][i]) and SpectralDB_Results['HMDBSMILES'][i] != \" \":\n",
    "#                 for j, row in Suspect_list.iterrows():\n",
    "#                     LHms2 = [Chem.MolFromSmiles(SpectralDB_Results['HMDBSMILES'][i]), Chem.MolFromSmiles(Suspect_list['SMILES'][j])]\n",
    "#                     LHfps2 = [AllChem.GetMorganFingerprintAsBitVect(x2,2, nBits=2048) for x2 in LHms2]\n",
    "#                     LHtn2 = DataStructs.FingerprintSimilarity(LHfps2[0],LHfps2[1])\n",
    "#                     if LHtn2 >= 0.9:\n",
    "#                         SpectralDB_Results.loc[i, 'HLsmiles'] = Suspect_list['SMILES'][j]\n",
    "#                         SpectralDB_Results.loc[i, 'HLname'] = Suspect_list['Name'][j]\n",
    "\n",
    "#         # add annotations and occurences\n",
    "#         for i, row in SpectralDB_Results.iterrows():\n",
    "#             if not isNaN(SpectralDB_Results['HLname'][i]):\n",
    "#                 SpectralDB_Results['occurence'][i] = SpectralDB_Results['occurence'][i] + 1\n",
    "#                 if SpectralDB_Results['annotation'][i] == \"none\":\n",
    "#                     SpectralDB_Results['annotation'][i] = 'Suspect_List'\n",
    "#                 else:\n",
    "#                     SpectralDB_Results['annotation'][i] = SpectralDB_Results['annotation'][i] + ', Suspect_List'\n",
    "    \n",
    "#     if db == \"gnps\" or db == \"gm\" or db == \"hg\" or db == \"all\":\n",
    "\n",
    "#         # add columns to the result from scoring_spec\n",
    "#         # these columns are for high similiarity canidtes between the databases and suspect list\n",
    "#         SpectralDB_Results['GLsmiles'] = np.nan\n",
    "#         SpectralDB_Results['GLname'] = np.nan\n",
    "\n",
    "\n",
    "#         for i, row in SpectralDB_Results.iterrows():\n",
    "\n",
    "#             if not isNaN(SpectralDB_Results['GNPSSMILES'][i]) and SpectralDB_Results['GNPSSMILES'][i] != \" \":\n",
    "#                 for k, row in Suspect_list.iterrows():\n",
    "#                     LGms2 = [Chem.MolFromSmiles(SpectralDB_Results['GNPSSMILES'][i]), Chem.MolFromSmiles(Suspect_list['SMILES'][k])]\n",
    "#                     LGfps2 = [AllChem.GetMorganFingerprintAsBitVect(x2,2, nBits=2048) for x2 in LGms2]\n",
    "#                     LGtn2 = DataStructs.FingerprintSimilarity(LGfps2[0],LGfps2[1])\n",
    "#                     if LGtn2 >= 0.9:\n",
    "#                         SpectralDB_Results.loc[i, 'GLsmiles'] = Suspect_list['SMILES'][k]\n",
    "#                         SpectralDB_Results.loc[i, 'GLname'] = Suspect_list['Name'][k]\n",
    "#         # add annotations and occurences\n",
    "#         for i, row in SpectralDB_Results.iterrows():\n",
    "#             if not isNaN(SpectralDB_Results['GLname'][i]):\n",
    "#                 SpectralDB_Results['occurence'][i] = SpectralDB_Results['occurence'][i] + 1\n",
    "#                 if SpectralDB_Results['annotation'][i] == \"none\":\n",
    "#                     SpectralDB_Results['annotation'][i] = 'Suspect_List'\n",
    "#                 else:\n",
    "#                     SpectralDB_Results['annotation'][i] = SpectralDB_Results['annotation'][i] + ', Suspect_List'\n",
    "    \n",
    "#     if db == \"mbank\" or db == \"gm\" or db == \"hm\" or db == \"all\":\n",
    "\n",
    "#         # add columns to the result from scoring_spec\n",
    "#         # these columns are for high similiarity canidtes between the databases and suspect list\n",
    "#         SpectralDB_Results['MLsmiles'] = np.nan\n",
    "#         SpectralDB_Results['MLname'] = np.nan\n",
    "\n",
    "\n",
    "#         for i, row in SpectralDB_Results.iterrows():\n",
    "#             if not isNaN(SpectralDB_Results['MBSMILES'][i]) and SpectralDB_Results['MBSMILES'][i] != \" \":\n",
    "#                 for l, row in Suspect_list.iterrows():\n",
    "#                     LMms2 = [Chem.MolFromSmiles(SpectralDB_Results['MBSMILES'][i]), Chem.MolFromSmiles(Suspect_list['SMILES'][l])]\n",
    "#                     LMfps2 = [AllChem.GetMorganFingerprintAsBitVect(x2,2, nBits=2048) for x2 in LMms2]\n",
    "#                     LMtn2 = DataStructs.FingerprintSimilarity(LMfps2[0],LMfps2[1])\n",
    "#                     if LMtn2 >= 0.9:\n",
    "#                         SpectralDB_Results.loc[i, 'MLsmiles'] = Suspect_list['SMILES'][l]\n",
    "#                         SpectralDB_Results.loc[i, 'MLname'] = Suspect_list['Name'][l]\n",
    "\n",
    "#         # add annotations and occurences\n",
    "#         for i, row in SpectralDB_Results.iterrows():\n",
    "#             if not isNaN(SpectralDB_Results['MLname'][i]):\n",
    "#                 SpectralDB_Results['occurence'][i] = SpectralDB_Results['occurence'][i] + 1\n",
    "#                 if SpectralDB_Results['annotation'][i] == \"none\":\n",
    "#                     SpectralDB_Results['annotation'][i] = 'Suspect_List'\n",
    "#                 else:\n",
    "#                     SpectralDB_Results['annotation'][i] = SpectralDB_Results['annotation'][i] + ', Suspect_List'\n",
    "                \n",
    "#     SpectralDB_Results.to_csv(input_dir + \"MetabolomicsResults/SpecDBvsSL.csv\")\n",
    "#     return(SpectralDB_Results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mawRpy)",
   "language": "python",
   "name": "mawrpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
